{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import outer, eye, ones, zeros, diag, log, sqrt, exp, pi\n",
    "from numpy.linalg import inv, solve\n",
    "from numpy.random import multivariate_normal as mvnormal, normal, gamma, beta, binomial\n",
    "from scipy.special import gammaln\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "\n",
    "from numpy import zeros\n",
    "from numpy.random import randn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import arange, min, max, sqrt, mean, std\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'invalid': 'warn', 'over': 'warn', 'under': 'ignore'}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.seterr(all='raise') # TODO REMOVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {
    "code_folding": [
     6
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aalto University, School of Science\n",
    "# T-61.5140 Machine Learning: Advanced probabilistic Methods\n",
    "# Author: antti.kangasraasio@aalto.fi, 2016\n",
    "\n",
    "mm_cumulative_error = 0.0 # TODO REMOVE\n",
    "mm_max_diff = 0.0 # TODO REMOVE\n",
    "\n",
    "class EM_algo():\n",
    "    \"\"\"\n",
    "        A superclass for different EM-fitted models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hyperparams, X=None, Y=None, ndata=0, pdata=0):\n",
    "        \"\"\"\n",
    "            Initialize model based either on given data (X, Y) or\n",
    "            on given data dimensionality (ndata, pdata).\n",
    "        \"\"\"\n",
    "        if not X is None and not Y is None:\n",
    "            self.X = X\n",
    "            self.Y = Y\n",
    "            self.ndata = len(self.X)\n",
    "            self.pdata = len(self.X[0])\n",
    "        if ndata and pdata:\n",
    "            self.X = None\n",
    "            self.Y = None\n",
    "            self.ndata = ndata\n",
    "            self.pdata = pdata\n",
    "        self.h = hyperparams\n",
    "        self.p = dict() # model parameters\n",
    "        self.reset()\n",
    "        if not X is None and not Y is None:\n",
    "            self.current_logl, self.cll = self.logl()\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            Reset priors and draw parameter estimates from prior.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Subclass implements\")\n",
    "\n",
    "\n",
    "    def draw(self, item):\n",
    "        \"\"\"\n",
    "            Draw a data sample from the current predictive distribution.\n",
    "            Returns the drawn y and z-values.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Subclass implements\")\n",
    "\n",
    "\n",
    "    def logl(self):\n",
    "        \"\"\"\n",
    "            Calculates the full log likelihood for this model.\n",
    "            Returns the logl (and the values of each term for debugging purposes)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Subclass implements\")\n",
    "\n",
    "\n",
    "    def EM_iter(self):\n",
    "        \"\"\"\n",
    "            Executes a single round of EM updates for this model.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Subclass implements\")\n",
    "\n",
    "\n",
    "    def EM_fit(self, alim=1e-10, maxit=1e4):\n",
    "        \"\"\"\n",
    "            Calls the EM_iter repeatedly until the log likelihood\n",
    "            of the model increases less than 'alim' in absolute\n",
    "            value or after 'maxit' iterations have been done.\n",
    "\n",
    "            Returns the number of EM-iterations, final log likelihood\n",
    "            value and a string that explains the end condition.\n",
    "        \"\"\"\n",
    "        logl, ll = self.logl()\n",
    "        for i in range(int(maxit)):\n",
    "            self.EM_iter()\n",
    "            logl2, ll2 = self.logl()\n",
    "            adiff = abs(logl2 - logl)\n",
    "            if adiff < alim:\n",
    "                return i+1, logl2, \"alim\"\n",
    "            logl = logl2\n",
    "        return maxit, logl2, \"maxit\"\n",
    "\n",
    "\n",
    "    def assert_logl_increased(self, event):\n",
    "        \"\"\"\n",
    "            Checks that the log likelihood increased since model\n",
    "            initialization or the time this function was last called.\n",
    "        \"\"\"\n",
    "        newlogl, ll = self.logl()\n",
    "        global mm_cumulative_error # TODO REMOVE\n",
    "        global mm_max_diff # TODO REMOVE\n",
    "        if self.current_logl > newlogl:\n",
    "            if mm_max_diff < self.current_logl - newlogl:\n",
    "                mm_max_diff = self.current_logl - newlogl\n",
    "            mm_cumulative_error = mm_cumulative_error + (self.current_logl - newlogl)\n",
    "#         if self.current_logl - newlogl > 10.0:\n",
    "        if self.current_logl - newlogl > 0.1:\n",
    "#         if self.current_logl - newlogl > 1e-3:\n",
    "#             if not self.icll is None:\n",
    "#             inewlogl, ill = self.incompletelogl()\n",
    "# #             self.debug_logl(self.icll, ill)\n",
    "#             self.debug_logl(self.cll, ll)\n",
    "# #             print(\"logl decreased after %s\" % (event))\n",
    "#             if self.current_ilogl - inewlogl > 1e-3:\n",
    "#                 raise ValueError(\"%s\" % (event))\n",
    "            raise RuntimeError(\"%s\" % (event))\n",
    "#             raise ValueError(\"%s\" % (event))\n",
    "#             raise ValueError(\"logl decreased after %s\" % (event))\n",
    "        self.current_logl, self.cll = newlogl, ll\n",
    "#         if not self.icll is None:\n",
    "#         self.current_ilogl, self.icll = self.incompletelogl()\n",
    "\n",
    "\n",
    "    def get_p(self):\n",
    "        \"\"\"\n",
    "            Returns a copy of the model parameters.\n",
    "        \"\"\"\n",
    "        return copy.deepcopy(self.p)\n",
    "\n",
    "\n",
    "    def set_p(self, p):\n",
    "        \"\"\"\n",
    "            Sets the model parameters.\n",
    "        \"\"\"\n",
    "        self.p = p.copy()\n",
    "\n",
    "\n",
    "    def print_p(self):\n",
    "        \"\"\"\n",
    "            Prints the model parameters, one at each line.\n",
    "        \"\"\"\n",
    "        for k, v in self.p.items():\n",
    "            print(\"%s = %s\" % (k, v))\n",
    "\n",
    "\n",
    "    def pretty_vector(self, x):\n",
    "        \"\"\"\n",
    "            Returns a formatted version of a vector.\n",
    "        \"\"\"\n",
    "        s = [\"(\"]\n",
    "        s.extend([\"%.2f, \" % (xi) for xi in x[:-1]])\n",
    "        s.append(\"%.2f)\" % (x[-1]))\n",
    "        return \"\".join(s)\n",
    "\n",
    "\n",
    "    def debug_logl(self, ll1, ll2):\n",
    "        \"\"\"\n",
    "            Prints an analysis of the per-term change in\n",
    "            log likelihood from ll1 to ll2.\n",
    "        \"\"\"\n",
    "        print(\"Logl      before     after\")\n",
    "        for v1, v2, i in zip(ll1, ll2, range(len(ll1))):\n",
    "            if v1 > v2:\n",
    "                d = \">\"\n",
    "            elif v2 > v1:\n",
    "                d = \"<\"\n",
    "            else:\n",
    "                d = \"=\"\n",
    "            print(\"Term %02d: %7.3f %s %7.3f\" % (i, v1, d, v2))\n",
    "        v1 = sum(ll1)\n",
    "        v2 = sum(ll2)\n",
    "        if v1 > v2:\n",
    "            d = \">\"\n",
    "        elif v2 > v1:\n",
    "            d = \"<\"\n",
    "        else:\n",
    "            d = \"=\"\n",
    "        diff = v2-v1\n",
    "        print(\"Total    %7.3f %s %7.3f   diff: %7.3f\" % (v1, d, v2, diff))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aalto University, School of Science\n",
    "# T-61.5140 Machine Learning: Advanced probabilistic Methods\n",
    "# Author: antti.kangasraasio@aalto.fi, 2016\n",
    "\n",
    "class EM_algo_LM_ML(EM_algo):\n",
    "    \"\"\"\n",
    "        A linear gaussian model. MAXLIKELIHOOD INSTEAD OF MAP\n",
    "    \"\"\"\n",
    "\n",
    "    def reset(self, responsibilities=None):\n",
    "        \"\"\"\n",
    "            Reset priors and draw parameter estimates from prior.\n",
    "        \"\"\"\n",
    "        # priors\n",
    "        self.lbd_phi0       = self.h[\"lbd_phi0\"]\n",
    "        self.alpha_s20      = self.h[\"alpha_s20\"]\n",
    "        self.beta_s20       = self.h[\"beta_s20\"]\n",
    "        self.sigma_phi0     = eye(self.pdata) * self.h[\"lbd_phi0\"]\n",
    "        self.sigma_phi0_inv = eye(self.pdata) / self.h[\"lbd_phi0\"]\n",
    "        self.mu_phi0        = ones(self.pdata) * self.h[\"mu_phi0\"]\n",
    "\n",
    "        # initial parameter estimates drawn from prior\n",
    "        self.p           = dict()\n",
    "        self.p[\"sigma2\"] = 1.0 / gamma(self.alpha_s20, 1.0 / self.beta_s20) # inverse gamma\n",
    "        self.p[\"phi\"]    = mvnormal(self.mu_phi0, self.p[\"sigma2\"] * self.sigma_phi0)\n",
    "        \n",
    "        if not responsibilities is None:\n",
    "            if not self.X is None and not self.Y is None:\n",
    "                self.current_logl, self.cll = self.logl()\n",
    "            \n",
    "\n",
    "\n",
    "    def draw(self, item):\n",
    "        \"\"\"\n",
    "            Draw a data sample from the current predictive distribution.\n",
    "            Returns the y-value (and a constant z-value for compatibility)\n",
    "        \"\"\"\n",
    "        mean = float(item.dot(self.p[\"phi\"]))\n",
    "        std  = sqrt(self.p[\"sigma2\"])\n",
    "        return normal(mean, std), 1\n",
    "\n",
    "\n",
    "    def logl(self, responsibilities=None):\n",
    "        \"\"\"\n",
    "            Calculates the full log likelihood for this model.\n",
    "            Returns the logl (and the values of each term for debugging purposes)\n",
    "        \"\"\"\n",
    "        ll    = zeros(8)\n",
    "#         phie  = self.p[\"phi\"] - self.mu_phi0\n",
    "        err   = (self.X.dot(self.p[\"phi\"]) - self.Y) ** 2\n",
    "        \n",
    "        if responsibilities is None:\n",
    "            # p(y)\n",
    "            ll[0] = - 0.5 * log(2 * pi * self.p[\"sigma2\"]) * self.ndata\n",
    "            ll[1] = sum(- 0.5 * err / self.p[\"sigma2\"])\n",
    "    #         # p(phi)\n",
    "    #         ll[2] = - 0.5 * log(2 * pi * self.lbd_phi0 * self.p[\"sigma2\"]) * self.pdata\n",
    "    #         ll[3] = - 0.5 * phie.T.dot(phie) / (self.lbd_phi0 * self.p[\"sigma2\"])\n",
    "    #         # p(sigma2)\n",
    "    #         ll[4] = self.alpha_s20 * log(self.beta_s20)\n",
    "    #         ll[5] = - gammaln(self.alpha_s20)\n",
    "    #         ll[6] = - (self.alpha_s20 + 1.0) * log(self.p[\"sigma2\"])\n",
    "    #         ll[7] = - self.beta_s20 / self.p[\"sigma2\"]\n",
    "        else:\n",
    "            for t in range(self.ndata):\n",
    "                tmp123 = 0.0\n",
    "                for p in range(self.pdata):\n",
    "                    tmp123 += self.p[\"phi\"][p] * self.X[t,p]\n",
    "                ll[0] += responsibilities[t] * norm.logpdf(self.Y[t], tmp123, sqrt(self.p[\"sigma2\"]))\n",
    "            # p(y)\n",
    "#             ll[0] = responsibilities.dot( norm.logpdf(self.Y, self.X.dot(self.p[\"phi\"]), sqrt(self.p[\"sigma2\"])) )\n",
    "#             ll[0] = - 0.5 * log(2 * pi * self.p[\"sigma2\"]) * sum(responsibilities) # TODO HOX: or np.sum\n",
    "#             ll[1] = responsibilities.dot(- 0.5 * err / self.p[\"sigma2\"])\n",
    "        return sum(ll), ll\n",
    "\n",
    "\n",
    "    def EM_iter(self, responsibilities=None):\n",
    "        \"\"\"\n",
    "            Executes a single round of EM updates for this model.\n",
    "\n",
    "            Has checks to make sure that updates increase logl and\n",
    "            that parameter values stay in sensible limits.\n",
    "        \"\"\"\n",
    "        if responsibilities is None:\n",
    "            # phi\n",
    "            sumxx         = self.X.T.dot(self.X)\n",
    "            sumxy         = self.X.T.dot(self.Y)\n",
    "            self.p[\"phi\"] = solve(sumxx, sumxy)\n",
    "            self.assert_logl_increased(\"phi update\")\n",
    "\n",
    "            # sigma2\n",
    "            err  = (self.X.dot(self.p[\"phi\"]) - self.Y) ** 2\n",
    "            num  = sum(err)\n",
    "            den  = self.ndata\n",
    "            self.p[\"sigma2\"] = num / den\n",
    "            if self.p[\"sigma2\"] < 0.0:\n",
    "                raise ValueError(\"sigma2 < 0.0\")\n",
    "            self.assert_logl_increased(\"sigma2 update\")\n",
    "        else:\n",
    "            # phi\n",
    "            resp_matrix = eye(self.ndata) * responsibilities\n",
    "            sumxx = self.X.T.dot(resp_matrix.dot(self.X))\n",
    "            sumxy = responsibilities.T.dot( (self.Y * self.X.T).T )\n",
    "            self.p[\"phi\"] = solve(sumxx, sumxy)\n",
    "#             self.assert_logl_increased(\"phi update\")\n",
    "\n",
    "            # sigma2\n",
    "            phiX = self.p[\"phi\"].dot(self.X.T)\n",
    "            err = responsibilities.dot((self.Y - phiX)**2)\n",
    "            num = err\n",
    "            den = np.sum(responsibilities)\n",
    "            self.p[\"sigma2\"] = num / den\n",
    "            if self.p[\"sigma2\"] < 0.0:\n",
    "                print(phiX, err, den)\n",
    "                raise ValueError(\"sigma2 < 0.0\")\n",
    "#             self.assert_logl_increased(\"sigma2 update\")\n",
    "\n",
    "\n",
    "    def print_p(self):\n",
    "        \"\"\"\n",
    "            Prints the model parameters, one at each line.\n",
    "        \"\"\"\n",
    "        print(\"phi    : %s\" % (self.pretty_vector(self.p[\"phi\"])))\n",
    "        print(\"sigma2 : %.3f\" % (self.p[\"sigma2\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aalto University, School of Science\n",
    "# T-61.5140 Machine Learning: Advanced probabilistic Methods\n",
    "# Author: antti.kangasraasio@aalto.fi, 2016\n",
    "\n",
    "class EM_algo_LM(EM_algo):\n",
    "    \"\"\"\n",
    "        A linear gaussian model.\n",
    "    \"\"\"\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            Reset priors and draw parameter estimates from prior.\n",
    "        \"\"\"\n",
    "        # priors\n",
    "        self.lbd_phi0       = self.h[\"lbd_phi0\"]\n",
    "        self.alpha_s20      = self.h[\"alpha_s20\"]\n",
    "        self.beta_s20       = self.h[\"beta_s20\"]\n",
    "        self.sigma_phi0     = eye(self.pdata) * self.h[\"lbd_phi0\"]\n",
    "        self.sigma_phi0_inv = eye(self.pdata) / self.h[\"lbd_phi0\"]\n",
    "        self.mu_phi0        = ones(self.pdata) * self.h[\"mu_phi0\"]\n",
    "\n",
    "        # initial parameter estimates drawn from prior\n",
    "        self.p           = dict()\n",
    "        self.p[\"sigma2\"] = 1.0 / gamma(self.alpha_s20, 1.0 / self.beta_s20) # inverse gamma\n",
    "        self.p[\"phi\"]    = mvnormal(self.mu_phi0, self.p[\"sigma2\"] * self.sigma_phi0)\n",
    "\n",
    "\n",
    "    def draw(self, item):\n",
    "        \"\"\"\n",
    "            Draw a data sample from the current predictive distribution.\n",
    "            Returns the y-value (and a constant z-value for compatibility)\n",
    "        \"\"\"\n",
    "        mean = float(item.dot(self.p[\"phi\"]))\n",
    "        std  = sqrt(self.p[\"sigma2\"])\n",
    "        return normal(mean, std), 1\n",
    "\n",
    "\n",
    "    def logl(self):\n",
    "        \"\"\"\n",
    "            Calculates the full log likelihood for this model.\n",
    "            Returns the logl (and the values of each term for debugging purposes)\n",
    "        \"\"\"\n",
    "        ll    = zeros(8)\n",
    "        phie  = self.p[\"phi\"] - self.mu_phi0\n",
    "#         print(\"phie\", phie.shape)\n",
    "        err   = (self.X.dot(self.p[\"phi\"]) - self.Y) ** 2\n",
    "#         print(\"err\", err.shape)\n",
    "        # p(y)\n",
    "        ll[0] = - 0.5 * log(2 * pi * self.p[\"sigma2\"]) * self.ndata\n",
    "        ll[1] = sum(- 0.5 * err / self.p[\"sigma2\"])\n",
    "        # p(phi)\n",
    "        ll[2] = - 0.5 * log(2 * pi * self.lbd_phi0 * self.p[\"sigma2\"]) * self.pdata\n",
    "        ll[3] = - 0.5 * phie.T.dot(phie) / (self.lbd_phi0 * self.p[\"sigma2\"])\n",
    "        # p(sigma2)\n",
    "        ll[4] = self.alpha_s20 * log(self.beta_s20)\n",
    "        ll[5] = - gammaln(self.alpha_s20)\n",
    "        ll[6] = - (self.alpha_s20 + 1.0) * log(self.p[\"sigma2\"])\n",
    "        ll[7] = - self.beta_s20 / self.p[\"sigma2\"]\n",
    "        return sum(ll), ll\n",
    "\n",
    "\n",
    "    def EM_iter(self):\n",
    "        \"\"\"\n",
    "            Executes a single round of EM updates for this model.\n",
    "\n",
    "            Has checks to make sure that updates increase logl and\n",
    "            that parameter values stay in sensible limits.\n",
    "        \"\"\"\n",
    "        # phi\n",
    "        sumxx         = self.X.T.dot(self.X)\n",
    "        sumxy         = self.X.T.dot(self.Y)\n",
    "        sigma_mu      = self.sigma_phi0_inv.dot(self.mu_phi0)\n",
    "        sigma_phi_inv = self.sigma_phi0_inv + sumxx\n",
    "#         print(\"sigma_phi_inv.shape\", sigma_phi_inv.shape)\n",
    "        self.p[\"phi\"] = solve(sigma_phi_inv, sigma_mu + sumxy)\n",
    "#         print(\"sumxx\", type(sumxx), \"sumxy\", type(sumxy), \"sigma_mu\", type(sigma_mu), \"sigma_phi_inv\", type(sigma_phi_inv))\n",
    "#         print(\"sumxx\", sumxx.shape, \"sumxy\", sumxy.shape, \"sigma_mu\", sigma_mu.shape, \"sigma_phi_inv\", sigma_phi_inv.shape)\n",
    "        self.assert_logl_increased(\"phi update\")\n",
    "\n",
    "        # sigma2\n",
    "        phie = (self.p[\"phi\"] - self.mu_phi0) ** 2\n",
    "        err  = (self.X.dot(self.p[\"phi\"]) - self.Y) ** 2\n",
    "        num  = self.beta_s20 + 0.5 * sum(err) + 0.5 * sum(phie) / self.lbd_phi0\n",
    "        den  = self.alpha_s20 + 1.0 + 0.5 * (self.ndata + self.pdata)\n",
    "        self.p[\"sigma2\"] = num / den\n",
    "#         print(\"phie\", type(phie), \"err\", type(err), \"num\", type(num), \"den\", type(den))\n",
    "#         print(\"phie\", phie.shape, \"err\", err.shape, \"num\", num.shape, \"den\", \"is a float\")\n",
    "        if self.p[\"sigma2\"] < 0.0:\n",
    "            raise ValueError(\"sigma2 < 0.0\")\n",
    "        self.assert_logl_increased(\"sigma2 update\")\n",
    "\n",
    "\n",
    "    def print_p(self):\n",
    "        \"\"\"\n",
    "            Prints the model parameters, one at each line.\n",
    "        \"\"\"\n",
    "        print(\"phi    : %s\" % (self.pretty_vector(self.p[\"phi\"])))\n",
    "        print(\"sigma2 : %.3f\" % (self.p[\"sigma2\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aalto University, School of Science\n",
    "# T-61.5140 Machine Learning: Advanced probabilistic Methods\n",
    "# Author: antti.kangasraasio@aalto.fi, 2016\n",
    "\n",
    "def generate_X(ndata, pdata):\n",
    "    \"\"\"\n",
    "        Return a matrix of normally distributed random values.\n",
    "    \"\"\"\n",
    "    X = randn(ndata, pdata)\n",
    "    return X\n",
    "\n",
    "\n",
    "def generate_YZ(X, distribution):\n",
    "    \"\"\"\n",
    "        Draw observations Y and latent variable values Z from a distribution.\n",
    "    \"\"\"\n",
    "    ndata = len(X)\n",
    "    Y = zeros(ndata)\n",
    "    Z = zeros(ndata)\n",
    "    for i in range(ndata):\n",
    "        Y[i], Z[i] = distribution.draw(X[i])\n",
    "    return Y, Z\n",
    "\n",
    "\n",
    "def get_hyperp():\n",
    "    \"\"\"\n",
    "        Return model hyperparameters.\n",
    "    \"\"\"\n",
    "    return {\n",
    "            \"alpha_s20\": 5.0,\n",
    "            \"beta_s20\" : 1.0,\n",
    "            \"lbd_phi0\" : 1.0,\n",
    "            \"mu_phi0\"  : 0.0,\n",
    "            \"alpha_w0\" : 3.0,\n",
    "            \"beta_w0\"  : 3.0,\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixture model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EM_algo_MM_ML666(EM_algo):\n",
    "    \"\"\"\n",
    "        A mixture of two linear models, ML instead of MAP.\n",
    "    \"\"\"\n",
    "#     def __init__(self, hyperparams, X=None, Y=None, ndata=0, pdata=0):\n",
    "#         super().__init__(hyperparams, X, Y, ndata, pdata)\n",
    "# #         self.L1 = EM_algo_LM_ML(hyperparams, X, Y, ndata, pdata)\n",
    "# #         self.L2 = EM_algo_LM_ML(hyperparams, X, Y, ndata, pdata)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            Reset priors and draw parameter estimates from prior.\n",
    "        \"\"\"\n",
    "        \n",
    "#         print(\"PARAMS\", self.h, self.X, self.Y, self.ndata, self.pdata)\n",
    "        \n",
    "        self.L1 = EM_algo_LM_ML(self.h, X=self.X, Y=self.Y)\n",
    "        self.L2 = EM_algo_LM_ML(self.h, X=self.X, Y=self.Y)\n",
    "        \n",
    "        # priors\n",
    "        self.alpha_w0       = self.h[\"alpha_w0\"]\n",
    "        self.beta_w0        = self.h[\"beta_w0\"]\n",
    "        \n",
    "        # initial parameter estimates drawn from prior\n",
    "        self.p             = dict()\n",
    "        # Weights\n",
    "        self.p[\"w\"]        = beta(self.alpha_w0, self.beta_w0)\n",
    "        # Responsibilities (TODO: do we need this here?)\n",
    "        self.gamma          = binomial(1, self.p[\"w\"], self.ndata)\n",
    "        \n",
    "        self.L1.reset(self.gamma)\n",
    "        self.L2.reset(1-self.gamma)\n",
    "        \n",
    "#         if not self.X is None and not self.Y is None:\n",
    "#             self.current_ilogl, self.icll = self.incompletelogl()\n",
    "\n",
    "\n",
    "    def draw(self, item):\n",
    "        \"\"\"\n",
    "            Draw a data sample from the current predictive distribution.\n",
    "            Returns the y-value and z-value\n",
    "        \"\"\"\n",
    "        \n",
    "        if np.random.rand() < self.p[\"w\"]:\n",
    "            y, z1 = self.L1.draw()\n",
    "            return y, 1\n",
    "        else:\n",
    "            y, z1 = self.L2.draw()\n",
    "            return y, 2\n",
    "\n",
    "\n",
    "    def logl(self):\n",
    "        \"\"\"\n",
    "            Calculates the full log likelihood for this model.\n",
    "            Returns the logl (and the values of each term for debugging purposes)\n",
    "        \"\"\"\n",
    "                \n",
    "        ll         = zeros(20)\n",
    "        \n",
    "        L1_tot, L1_ll = self.L1.logl(self.gamma)\n",
    "        L2_tot, L2_ll = self.L2.logl(1-self.gamma)\n",
    "        ll[0] = L1_ll[0]\n",
    "        ll[1] = L1_ll[1]\n",
    "        ll[2] = L2_ll[0]\n",
    "        ll[3] = L2_ll[1]\n",
    "        \n",
    "        ll[4] = 2*np.sum(self.gamma) * log(self.p[\"w\"])\n",
    "        ll[5] = 2*np.sum(1-self.gamma) * log(1-self.p[\"w\"])\n",
    "        \n",
    "#         ll[4] = np.sum(L1_ll[2:])\n",
    "#         ll[5] = np.sum(L2_ll[2:])\n",
    "        \n",
    "        ### p(w)\n",
    "#         ll[6] = log(gamma(self.alpha_w0 + self.beta_w0)) - log(gammaln(self.alpha_w0)) - log(gammaln(self.beta_w0))\n",
    "#         ll[7] = (self.alpha_w0 - 1) * self.p[\"w\"]\n",
    "#         ll[8] = (self.beta_w0  - 1) * (1 - self.p[\"w\"])\n",
    "        \n",
    "        return np.sum(ll), ll\n",
    "    \n",
    "    \n",
    "    def incompletelogl(self):\n",
    "        \"\"\"\n",
    "            Calculates the incomplete data log likelihood for this model.\n",
    "            Returns the logl (and the values of each term for debugging purposes)\n",
    "        \"\"\"\n",
    "        ll    = zeros(2)\n",
    "\n",
    "        ll[0] = self.p[\"w\"] * norm.pdf(self.Y, self.X.dot(self.L1.p[\"phi\"]), sqrt(self.L1.p[\"sigma2\"]))\n",
    "        ll[1] = (1-self.p[\"w\"]) * norm.pdf(self.Y, self.X.dot(self.L2.p[\"phi\"]), sqrt(self.L2.p[\"sigma2\"]))\n",
    "        \n",
    "        return np.sum(ll), ll\n",
    "\n",
    "\n",
    "    def EM_iter(self):\n",
    "        \"\"\"\n",
    "            Executes a single round of EM updates for this model.\n",
    "\n",
    "            Has checks to make sure that updates increase logl and\n",
    "            that parameter values stay in sensible limits.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.current_logl, self.cll = self.logl()\n",
    "        \n",
    "        # ==================== E-STEP ====================\n",
    "        propto_gamma1 =      self.p[\"w\"]  * norm.pdf(self.Y, self.X.dot(self.L1.p[\"phi\"]), sqrt(self.L1.p[\"sigma2\"]))\n",
    "        propto_gamma2 = (1 - self.p[\"w\"]) * norm.pdf(self.Y, self.X.dot(self.L2.p[\"phi\"]), sqrt(self.L2.p[\"sigma2\"]))\n",
    "#         propto_gamma1x =    log(self.p[\"w\"])  * norm.logpdf(self.Y, self.X.dot(self.L1.p[\"phi\"]), sqrt(self.L1.p[\"sigma2\"]))\n",
    "#         propto_gamma2x = log(1 - self.p[\"w\"]) * norm.logpdf(self.Y, self.X.dot(self.L2.p[\"phi\"]), sqrt(self.L2.p[\"sigma2\"]))\n",
    "        self.gamma = propto_gamma1 / (propto_gamma1 + propto_gamma2)\n",
    "#         print(\"GAMMADIFF\", np.sum((propto_gamma1 / (propto_gamma1 + propto_gamma2) - (propto_gamma1x / (propto_gamma1x + propto_gamma2x)))))\n",
    "        \n",
    "        # ==================== M-STEP ====================\n",
    "        \n",
    "        self.L1.EM_iter(self.gamma)\n",
    "        self.L2.EM_iter(1-self.gamma)\n",
    "        \n",
    "#         self.assert_logl_increased(\"L1,L2\")\n",
    "        \n",
    "        self.p[\"w\"] = sum(self.gamma) / self.ndata\n",
    "        self.assert_logl_increased(\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "w",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-978-3cf0d8ed7779>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# model = EM_algo_MM(hyperp, X, Y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEM_algo_MM_ML666\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEM_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model fit (logl %.2f) after %d iterations (%s reached)\"\u001b[0m \u001b[0;34m%\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mlogl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-973-818f23a3c787>\u001b[0m in \u001b[0;36mEM_fit\u001b[0;34m(self, alim, maxit)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mlogl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEM_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mlogl2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0madiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogl2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-977-d55e9effae95>\u001b[0m in \u001b[0;36mEM_iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_logl_increased\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-973-818f23a3c787>\u001b[0m in \u001b[0;36massert_logl_increased\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;31m#             if self.current_ilogl - inewlogl > 1e-3:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;31m#                 raise ValueError(\"%s\" % (event))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;31m#             raise ValueError(\"%s\" % (event))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;31m#             raise ValueError(\"logl decreased after %s\" % (event))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: w"
     ]
    }
   ],
   "source": [
    "# generate a model for estimating the parameters of the\n",
    "# true model based on the observations (X, Y) we just made\n",
    "# model = EM_algo_MM(hyperp, X, Y)\n",
    "model = EM_algo_MM_ML666(hyperp, X, Y)\n",
    "i, logl, r = model.EM_fit()\n",
    "print(\"Model fit (logl %.2f) after %d iterations (%s reached)\" % \\\n",
    "        (logl, i, r))\n",
    "print(\"\")\n",
    "print(\"MAP estimate of true model parameters:\")\n",
    "model.print_p()\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60224419737558221"
      ]
     },
     "execution_count": 979,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.p[\"w\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIwAAAJeCAYAAADWcJ6xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nANQQGAEAAAAAAKCGwAgAAAAAAAA1/x9LCQUslLS1bQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1198259b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if possible, plot samples, true model and estimated model\n",
    "if pdata == 1:\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.scatter(X, Y, s=20, c='black', label=\"Training data\")\n",
    "#         plt.scatter(X_v, Y_v, s=20, c='orange', label=\"Validation data\")\n",
    "    x = arange(min(X)-0.1, max(X)+0.1, 0.1)\n",
    "#         print_linear_model(x, true_model.get_p()[\"phi\"], \\\n",
    "#                 true_model.get_p()[\"sigma2\"], 'red', \"True model\")\n",
    "#         print_linear_model(x, model.get_p()[\"phi\"], \\\n",
    "#                 model.get_p()[\"sigma2\"], 'blue', \"Predicted model\")\n",
    "\n",
    "    y = true_model.p[\"phi_1\"] * x\n",
    "    color = 'orange'\n",
    "    plt.plot(x, y, color, label=\"true1\")\n",
    "#     plt.fill_between(x, y + 1.96 * sqrt(true_model.p[\"sigma2_1\"]), y - 1.96 * sqrt(true_model.p[\"sigma2_1\"]), alpha=0.1, facecolor=color, interpolate=True)\n",
    "    \n",
    "    y = true_model.p[\"phi_2\"] * x\n",
    "    color = 'green'\n",
    "    plt.plot(x, y, color, label=\"true1\")\n",
    "#     plt.fill_between(x, y + 1.96 * sqrt(true_model.p[\"sigma2_2\"]), y - 1.96 * sqrt(true_model.p[\"sigma2_2\"]), alpha=0.1, facecolor=color, interpolate=True)\n",
    "\n",
    "    # Components\n",
    "    y = model.L1.p[\"phi\"] * x\n",
    "    color = 'red'\n",
    "    plt.plot(x, y, color, label=\"component1\")\n",
    "    plt.fill_between(x, y + 1.96 * sqrt(model.L1.p[\"sigma2\"]), y - 1.96 * sqrt(model.L1.p[\"sigma2\"]), alpha=0.25, facecolor=color, interpolate=True)\n",
    "\n",
    "    y = model.L2.p[\"phi\"] * x\n",
    "    color = 'blue'\n",
    "    plt.plot(x, y, color, label=\"component2\")\n",
    "    plt.fill_between(x, y + 1.96 * sqrt(model.L2.p[\"sigma2\"]), y - 1.96 * sqrt(model.L2.p[\"sigma2\"]), alpha=0.25, facecolor=color, interpolate=True)\n",
    "\n",
    "    plt.legend(loc=1)\n",
    "    plt.xlim(min(x), max(x))\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "\n",
    "# @jit\n",
    "def update_phi(responsibilities, Y, X, mu_phi0, sigma_phi0_inv):\n",
    "    # responsibilities = gamma\n",
    "    T = len(Y)\n",
    "    P = X.shape[1]\n",
    "    sum_gammayx = np.zeros(P)\n",
    "    sum_gammaxx = np.zeros((P, P))\n",
    "    gammax = np.zeros((T, P)) # gamma (1xT) elementwise* X (TxP) => gammax (TxP)\n",
    "    \n",
    "    for t in range(T):\n",
    "        for p in range(P):\n",
    "            sum_gammayx[p] += responsibilities[t] * Y[t] * X[t,p]\n",
    "    \n",
    "    for t in range(T):\n",
    "        for p in range(P):\n",
    "            gammax[t, p] += responsibilities[t] * X[t,p]\n",
    "    \n",
    "    for t in range(T):\n",
    "        for p in range(p):\n",
    "            sum_gammaxx[p] += gammax[t,p] * X[t,p]\n",
    "        \n",
    "#     sum_gammayx_o     = responsibilities.T.dot(Y * X)\n",
    "#     sum_gammaxx_o     = np.dot( X.T, (responsibilities.T * X) )\n",
    "#     print(\"sum_gammayx\", sum_gammayx.shape, \"sum_gammaxx\", sum_gammaxx.shape)\n",
    "    sigma_mu        = sigma_phi0_inv.dot(mu_phi0)\n",
    "    sigma_phi_inv   = sigma_phi0_inv + sum_gammaxx\n",
    "    return solve(sigma_phi_inv, sigma_mu + sum_gammayx)\n",
    "\n",
    "\n",
    "def update_sigma_ml(phi, responsibilities, Y, X):\n",
    "    T = len(Y)\n",
    "    P = X.shape[1]\n",
    "    \n",
    "#     err = 0.0\n",
    "#     for t in range(T):\n",
    "#         for p in range(P):\n",
    "#             err += responsibilities[t] * (Y[t] - phi[p]*X[t,p])**2\n",
    "\n",
    "    err = 0.0\n",
    "    for t in range(T):\n",
    "        jup = 0.0\n",
    "        for p in range(P):\n",
    "            jup += phi[p]*X[t,p]\n",
    "        err += responsibilities[t] * (Y[t] - jup)**2\n",
    "        \n",
    "#     phiX1 = phi.dot(X.T)\n",
    "#     target_err1 = (Y - phiX1)**2\n",
    "#     err1 = responsibilities.dot(target_err1)\n",
    "#     old = err1/np.sum(responsibilities)\n",
    "    new = err / np.sum(responsibilities)\n",
    "#     print(\"SIGMA OLD NEW\", old, new)\n",
    "#     print(\"SIGMA DIFF\", old-new)\n",
    "    return new\n",
    "#     return err / np.sum(responsibilities)\n",
    "    \n",
    "\n",
    "@jit\n",
    "def update_phi_ml(responsibilities, Y, X):\n",
    "    # responsibilities = gamma\n",
    "    T = len(Y)\n",
    "    P = X.shape[1]\n",
    "    sum_gammayx = np.zeros(P)\n",
    "    sum_gammaxx = np.zeros((P, P))\n",
    "    gammax = np.zeros((T, P)) # gamma (1xT) elementwise* X (TxP) => gammax (TxP)\n",
    "    \n",
    "    for t in range(T):\n",
    "        for p in range(P):\n",
    "            sum_gammayx[p] += responsibilities[t] * Y[t] * X[t,p]\n",
    "    \n",
    "    for t in range(T):\n",
    "        for p in range(P):\n",
    "            gammax[t, p] += responsibilities[t] * X[t,p]\n",
    "            \n",
    "#     foobuz = X.T.dot(gammax)\n",
    "#     print(foobuz)\n",
    "    \n",
    "    for t in range(T): # x^T cdot gammax -> PxP\n",
    "        for p1 in range(P):\n",
    "            for p2 in range(P):\n",
    "                sum_gammaxx[p1,p2] += X[t,p1] * gammax[t,p2]\n",
    "    \n",
    "#     print(\"X SHAPE\", X.shape, \"Y SHAPE\", Y.shape, \"GAMMA SHAPE\", responsibilities.shape)\n",
    "    \n",
    "#     sum_gammayx_1 = responsibilities.T.dot( (Y * X.T).T )\n",
    "#     sum_gammaxx_1 = np.dot( X.T, (responsibilities * X.T).T )\n",
    "#     print(\"sum_gammayx_1\", sum_gammayx_1.shape, \"sum_gammaxx_1\", sum_gammaxx_1.shape)\n",
    "#     sum_gammayx_o     = responsibilities.T.dot(Y * X)\n",
    "#     sum_gammaxx_o     = np.dot( X.T, (responsibilities.T * X) )\n",
    "#     print(\"sum_gammayx\", sum_gammayx.shape, \"sum_gammaxx\", sum_gammaxx.shape)\n",
    "#     print(\"sum_gammayx\", sum_gammayx)\n",
    "#     print(\"sum_gammaxx\", sum_gammaxx)\n",
    "#     print(\"TESTDIFF\", sum_gammaxx_1 - foobuz)\n",
    "#     print(\"DIFF SUM YX\", np.sum(sum_gammayx - sum_gammayx_1))\n",
    "#     print(\"DIFF SUM XX\", np.sum(sum_gammaxx - sum_gammaxx_1))\n",
    "#     print(\"DIFF YX\", sum_gammayx - sum_gammayx_1)\n",
    "#     print(\"DIFF XX\", sum_gammaxx - sum_gammaxx_1)\n",
    "    return solve(sum_gammaxx, sum_gammayx)\n",
    "\n",
    "# @jit\n",
    "# def update_phi(responsibilities, Y, X, mu_phi0, sigma_phi0_inv):\n",
    "#     # responsibilities = gamma\n",
    "#     sum_gammayx     = responsibilities.T.dot(Y * X)\n",
    "#     sum_gammaxx     = np.dot( X.T, (responsibilities.T * X) )\n",
    "#     sigma_mu        = sigma_phi0_inv.dot(mu_phi0)\n",
    "#     sigma_phi_inv   = sigma_phi0_inv + sum_gammaxx\n",
    "#     return solve(sigma_phi_inv, sigma_mu + sum_gammayx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeje = np.array([1,2,3,4.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.,   4.,   9.,  16.])"
      ]
     },
     "execution_count": 983,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeje**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EM_algo_MM_ML(EM_algo):\n",
    "    \"\"\"\n",
    "        A mixture of two linear models, ML instead of MAP.\n",
    "    \"\"\"\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            Reset priors and draw parameter estimates from prior.\n",
    "        \"\"\"\n",
    "        # priors\n",
    "        self.alpha_w0       = self.h[\"alpha_w0\"]\n",
    "        self.beta_w0        = self.h[\"beta_w0\"]\n",
    "\n",
    "        # Same priors for phi1 and phi2, s2_1, s2_2, don't bother to copy vars twice\n",
    "        # i.e. alpha_s2_1_0 = alpha_s2_2_0 = alpha_s20\n",
    "        self.lbd_phi0       = self.h[\"lbd_phi0\"]\n",
    "        self.alpha_s20      = self.h[\"alpha_s20\"]\n",
    "        self.beta_s20       = self.h[\"beta_s20\"]\n",
    "        self.sigma_phi0     = eye(self.pdata) * self.h[\"lbd_phi0\"]\n",
    "        self.sigma_phi0_inv = eye(self.pdata) / self.h[\"lbd_phi0\"]\n",
    "        self.mu_phi0        = ones(self.pdata) * self.h[\"mu_phi0\"]\n",
    "        \n",
    "        # initial parameter estimates drawn from prior\n",
    "        self.p             = dict()\n",
    "        # Weights\n",
    "        self.p[\"w\"]        = beta(self.alpha_w0, self.beta_w0)\n",
    "        # Responsibilities (TODO: do we need this here?)\n",
    "        self.p[\"gamma\"]    = binomial(1, self.p[\"w\"], self.ndata)\n",
    "#         print(\"INIT GAMMA TYPE\", type(self.p[\"gamma\"]))\n",
    "#         print(\"INIT GAMMA SHAPE\", self.p[\"gamma\"].shape)\n",
    "        # Component 1\n",
    "        self.p[\"sigma2_1\"] = 1.0 / gamma(self.alpha_s20, 1.0 / self.beta_s20) # inverse gamma\n",
    "        self.p[\"phi_1\"]    = mvnormal(self.mu_phi0, self.p[\"sigma2_1\"] * self.sigma_phi0)\n",
    "#         print(\"INIT PHI1 SHAPE\", self.p[\"phi_1\"].shape)\n",
    "        # Component 2\n",
    "        self.p[\"sigma2_2\"] = 1.0 / gamma(self.alpha_s20, 1.0 / self.beta_s20) # inverse gamma\n",
    "        self.p[\"phi_2\"]    = mvnormal(self.mu_phi0, self.p[\"sigma2_2\"] * self.sigma_phi0)\n",
    "        \n",
    "        if not self.X is None and not self.Y is None:\n",
    "            self.current_ilogl, self.icll = self.incompletelogl()\n",
    "\n",
    "\n",
    "    def draw(self, item):\n",
    "        \"\"\"\n",
    "            Draw a data sample from the current predictive distribution.\n",
    "            Returns the y-value and z-value\n",
    "        \"\"\"\n",
    "        mean1 = float(item.dot(self.p[\"phi_1\"]))\n",
    "        std1  = sqrt(self.p[\"sigma2_1\"])\n",
    "        mean2 = float(item.dot(self.p[\"phi_2\"]))\n",
    "        std2  = sqrt(self.p[\"sigma2_2\"])\n",
    "        \n",
    "        if np.random.rand() < self.p[\"w\"]:\n",
    "            return normal(mean1, std1), 1\n",
    "        else:\n",
    "            return normal(mean2, std2), 2\n",
    "\n",
    "\n",
    "    def logl(self):\n",
    "        \"\"\"\n",
    "            Calculates the full log likelihood for this model.\n",
    "            Returns the logl (and the values of each term for debugging purposes)\n",
    "        \"\"\"\n",
    "        \n",
    "#         return self.incompletelogl()\n",
    "                \n",
    "        ll         = zeros(4)\n",
    "#         phi_1_diff = self.p[\"phi_1\"] - self.mu_phi0\n",
    "# #         print(\"phi_1_diff\", phi_1_diff.shape)\n",
    "#         phi_2_diff = self.p[\"phi_2\"] - self.mu_phi0\n",
    "#         phi_1_err  = phi_1_diff.T.dot(phi_1_diff)\n",
    "# #         print(\"phi_1_err\", phi_1_err.shape)\n",
    "#         phi_2_err  = phi_2_diff.T.dot(phi_2_diff)\n",
    "# #         err_1      = (self.X.dot(self.p[\"phi_1\"]) - self.Y) ** 2\n",
    "# #         err_2      = (self.X.dot(self.p[\"phi_2\"]) - self.Y) ** 2\n",
    "# #         print(\"phi1\", self.p[\"phi_1\"].shape)\n",
    "#         err_1      = (self.Y - self.X.dot(self.p[\"phi_1\"])) ** 2\n",
    "# #         print(\"err\", err_1.shape)\n",
    "# #         print(\"self.Y\", self.Y.shape, Y.shape)\n",
    "# #         print(\"self.X.dot(self.p[phi_1])\", self.X.dot(self.p[\"phi_1\"]).shape)\n",
    "#         err_2      = (self.Y - self.X.dot(self.p[\"phi_2\"])) ** 2\n",
    "        \n",
    "        # Responsibilities\n",
    "#         propto_gamma1 =      self.p[\"w\"]  * norm.pdf(self.Y, self.X.dot(self.p[\"phi_1\"]), sqrt(self.p[\"sigma2_1\"]))\n",
    "#         propto_gamma2 = (1 - self.p[\"w\"]) * norm.pdf(self.Y, self.X.dot(self.p[\"phi_2\"]), sqrt(self.p[\"sigma2_2\"]))\n",
    "#         gamma = propto_gamma1 / (propto_gamma1 + propto_gamma2)\n",
    "        gamma = self.p[\"gamma\"]\n",
    "    \n",
    "#         ll[0] = log(self.p[\"w\"]) * np.sum(gamma)\n",
    "        ll[1] = gamma.dot(norm.logpdf(self.Y, self.X.dot(self.p[\"phi_1\"]), sqrt(self.p[\"sigma2_1\"])))\n",
    "#         ll[2] = log(1-self.p[\"w\"]) * np.sum(1-gamma)\n",
    "        ll[3] = gamma.dot(norm.logpdf(self.Y, self.X.dot(self.p[\"phi_2\"]), sqrt(self.p[\"sigma2_2\"])))\n",
    "        \n",
    "        ### posterior factorizes p(y,z,w,phi,sigma) = p(y)p(z)p(w)p(phi)p(sigma)\n",
    "        \n",
    "        ### p(y)\n",
    "#         ll[0] = self.p[\"w\"]       * (-0.5 * log(2 * pi * self.p[\"sigma2_1\"]) * self.ndata)\n",
    "#         ll[1] = self.p[\"w\"]       * np.sum(- 0.5 * err_1 / self.p[\"sigma2_1\"])\n",
    "#         ll[2] = (1 - self.p[\"w\"]) * (-0.5 * log(2 * pi * self.p[\"sigma2_2\"]) * self.ndata)\n",
    "#         ll[3] = (1 - self.p[\"w\"]) * np.sum(- 0.5 * err_2 / self.p[\"sigma2_2\"])\n",
    "\n",
    "#         wN1 =    gamma  * norm.pdf(self.Y, self.X.dot(self.p[\"phi_1\"]), sqrt(self.p[\"sigma2_1\"]))\n",
    "#         wN2 = (1-gamma) * norm.pdf(self.Y, self.X.dot(self.p[\"phi_2\"]), sqrt(self.p[\"sigma2_2\"]))\n",
    "#         ll[0] = np.sum( log( wN1 + wN2 ) )\n",
    "\n",
    "#         ll[0] =       gamma.dot(-0.5 * log(2 * pi * self.p[\"sigma2_1\"]) -0.5 * err_1 / self.p[\"sigma2_1\"])\n",
    "#         ll[1] = 0\n",
    "#         ll[2] = (1 - gamma).dot(-0.5 * log(2 * pi * self.p[\"sigma2_2\"]) -0.5 * err_2 / self.p[\"sigma2_2\"])\n",
    "#         ll[3] = 0\n",
    "\n",
    "#         ll[0] = -0.5 * log(2 * pi * self.p[\"sigma2_1\"]) * np.sum(gamma)\n",
    "#         ll[1] = gamma.dot(-0.5 * err_1 / self.p[\"sigma2_1\"])\n",
    "#         ll[2] = -0.5 * log(2 * pi * self.p[\"sigma2_2\"]) * np.sum(1 - gamma)\n",
    "#         ll[3] = (1 - gamma).dot(-0.5 * err_2 / self.p[\"sigma2_2\"])\n",
    "\n",
    "#         ll[0] = log(self.p[\"w\"]) * np.sum(gamma) - 0.5 * log(2 * pi * self.p[\"sigma2_1\"]) * np.sum(gamma)\n",
    "#         ll[1] = gamma.dot(-0.5 * err_1 / self.p[\"sigma2_1\"])\n",
    "#         ll[2] = log(1-self.p[\"w\"]) * np.sum(1-gamma) - 0.5 * log(2 * pi * self.p[\"sigma2_2\"]) * np.sum(1 - gamma)\n",
    "#         ll[3] = (1 - gamma).dot(-0.5 * err_2 / self.p[\"sigma2_2\"])\n",
    " \n",
    "        return np.sum(ll), ll\n",
    "\n",
    "\n",
    "    def incompletelogl(self):\n",
    "        \"\"\"\n",
    "            Calculates the incomplete data log likelihood for this model.\n",
    "            Returns the logl (and the values of each term for debugging purposes)\n",
    "        \"\"\"\n",
    "        ll         = zeros(20)\n",
    "        phi_1_diff = self.p[\"phi_1\"] - self.mu_phi0\n",
    "        phi_2_diff = self.p[\"phi_2\"] - self.mu_phi0\n",
    "        phi_1_err  = phi_1_diff.T.dot(phi_1_diff)\n",
    "        phi_2_err  = phi_2_diff.T.dot(phi_2_diff)\n",
    "        err_1      = (self.X.dot(self.p[\"phi_1\"]) - self.Y) ** 2\n",
    "        err_2      = (self.X.dot(self.p[\"phi_2\"]) - self.Y) ** 2\n",
    "\n",
    "        #         propto_gamma1 = np.zeros(self.ndata)\n",
    "#         for t in range(self.ndata):\n",
    "#             propto_gamma1[t] = self.p[\"w\"] * 1/(sqrt(2*pi*self.p[\"sigma2_1\"])) * np.exp(-0.5 * ((self.Y[t] - self.p[\"phi_1\"].dot(X[t].T))**2)/self.p[\"sigma2_1\"])\n",
    "#         propto_gamma2 = np.zeros(self.ndata)\n",
    "#         for t in range(self.ndata):\n",
    "#             propto_gamma2[t] = (1-self.p[\"w\"]) * 1/(sqrt(2*pi*self.p[\"sigma2_2\"])) * np.exp(-0.5 * ((self.Y[t] - self.p[\"phi_2\"].dot(X[t].T))**2)/self.p[\"sigma2_2\"])\n",
    "        \n",
    "        ### p(y)\n",
    "#         wN1 = np.zeros(self.ndata)\n",
    "#         for t in range(self.ndata):\n",
    "#             wN1 +=    self.p[\"w\"]  * 1/(sqrt(2*pi*self.p[\"sigma2_1\"])) * np.exp(-0.5 * ((self.Y[t] - self.p[\"phi_1\"].dot(X[t].T))**2)/self.p[\"sigma2_1\"])\n",
    "#         wN2 = np.zeros(self.ndata)\n",
    "#         for t in range(self.ndata):\n",
    "#             wN2 += (1-self.p[\"w\"]) * 1/(sqrt(2*pi*self.p[\"sigma2_2\"])) * np.exp(-0.5 * ((self.Y[t] - self.p[\"phi_2\"].dot(X[t].T))**2)/self.p[\"sigma2_2\"])\n",
    "#         wN1 =    self.p[\"w\"]  * norm.pdf(self.Y, self.X.dot(self.p[\"phi_1\"]), sqrt(self.p[\"sigma2_1\"]))\n",
    "#         wN2 = (1-self.p[\"w\"]) * norm.pdf(self.Y, self.X.dot(self.p[\"phi_2\"]), sqrt(self.p[\"sigma2_2\"]))\n",
    "\n",
    "#         wN1 = norm.logpdf(self.Y, self.X.dot(self.p[\"phi_1\"]), sqrt(self.p[\"sigma2_1\"]))\n",
    "#         wN2 = norm.logpdf(self.Y, self.X.dot(self.p[\"phi_2\"]), sqrt(self.p[\"sigma2_2\"]))\n",
    "#         ll[0] = log(self.p[\"w\"]) * self.ndata + log(1-self.p[\"w\"]) * self.ndata\n",
    "#         ll[1] = np.sum( wN1 + wN2 )\n",
    "\n",
    "        N1 = norm.pdf(self.Y, self.X.dot(self.p[\"phi_1\"]), sqrt(self.p[\"sigma2_1\"]))\n",
    "        N2 = norm.pdf(self.Y, self.X.dot(self.p[\"phi_2\"]), sqrt(self.p[\"sigma2_2\"]))\n",
    "        ll[0] = log(self.p[\"w\"]) * self.ndata + log(1-self.p[\"w\"]) * self.ndata\n",
    "        ll[1] = np.sum( np.log( self.p[\"w\"]*N1 + (1-self.p[\"w\"])*N2 ) )\n",
    "\n",
    "#         ll[0] =     log(self.p[\"w\"]) * (-0.5 * log(2 * pi * self.p[\"sigma2_1\"]) * self.ndata)\n",
    "#         ll[1] =     log(self.p[\"w\"]) * np.sum(- 0.5 * err_1 / self.p[\"sigma2_1\"])\n",
    "#         ll[2] = log(1 - self.p[\"w\"]) * (-0.5 * log(2 * pi * self.p[\"sigma2_2\"]) * self.ndata)\n",
    "#         ll[3] = log(1 - self.p[\"w\"]) * np.sum(- 0.5 * err_2 / self.p[\"sigma2_2\"])\n",
    "\n",
    "#         ll[0] = self.p[\"w\"]       * (-0.5 * log(2 * pi * self.p[\"sigma2_1\"]) * self.ndata)\n",
    "#         ll[1] = self.p[\"w\"]       * np.sum(- 0.5 * err_1 / self.p[\"sigma2_1\"])\n",
    "#         ll[2] = (1 - self.p[\"w\"]) * (-0.5 * log(2 * pi * self.p[\"sigma2_2\"]) * self.ndata)\n",
    "#         ll[3] = (1 - self.p[\"w\"]) * np.sum(- 0.5 * err_2 / self.p[\"sigma2_2\"])\n",
    "        \n",
    "        return np.sum(ll), ll\n",
    "\n",
    "\n",
    "    def EM_iter(self):\n",
    "        \"\"\"\n",
    "            Executes a single round of EM updates for this model.\n",
    "\n",
    "            Has checks to make sure that updates increase logl and\n",
    "            that parameter values stay in sensible limits.\n",
    "        \"\"\"\n",
    "        \n",
    "#         Y = self.Y.view()\n",
    "#         Y.shape = (self.ndata, 1) # set Y view shape\n",
    "\n",
    "        # ==================== E-STEP ====================\n",
    "\n",
    "        # ========== Responsibilities gamma ==========        \n",
    "        # norm.pdf works on a vector, returning probability for each separately\n",
    "        propto_gamma1 =      self.p[\"w\"]  * norm.pdf(self.Y, self.X.dot(self.p[\"phi_1\"]), sqrt(self.p[\"sigma2_1\"]))\n",
    "        propto_gamma2 = (1 - self.p[\"w\"]) * norm.pdf(self.Y, self.X.dot(self.p[\"phi_2\"]), sqrt(self.p[\"sigma2_2\"]))\n",
    "        \n",
    "#         propto_gamma1 = np.zeros(self.ndata)\n",
    "#         for t in range(self.ndata):\n",
    "#             propto_gamma1[t] = self.p[\"w\"] * 1/(sqrt(2*pi*self.p[\"sigma2_1\"])) * np.exp(-0.5 * ((self.Y[t] - self.p[\"phi_1\"].dot(X[t].T))**2)/self.p[\"sigma2_1\"])\n",
    "#         propto_gamma2 = np.zeros(self.ndata)\n",
    "#         for t in range(self.ndata):\n",
    "#             propto_gamma2[t] = (1-self.p[\"w\"]) * 1/(sqrt(2*pi*self.p[\"sigma2_2\"])) * np.exp(-0.5 * ((self.Y[t] - self.p[\"phi_2\"].dot(X[t].T))**2)/self.p[\"sigma2_2\"])\n",
    "        \n",
    "#         print(\"propto_gamma1\", propto_gamma1.shape, \"propto_gamma2\", propto_gamma2.shape)\n",
    "#         print(\"propto_gamma1_x\", propto_gamma1_x.shape, \"propto_gamma2_x\", propto_gamma2_x.shape)\n",
    "#         print(np.sum(propto_gamma1 - propto_gamma1_x), np.sum(propto_gamma2 - propto_gamma2_x))\n",
    "#         print(\"n\", propto_gamma1 > 1.0)\n",
    "#         print(\"x\", propto_gamma1_x > 1.0)\n",
    "#         print(propto_gamma1)\n",
    "#         print(propto_gamma1_x)\n",
    "        # elementwise, works because numpy\n",
    "        gamma = propto_gamma1 / (propto_gamma1 + propto_gamma2)\n",
    "#         print(\"gamma\", gamma.shape)\n",
    "#         gammaView = gamma.view()\n",
    "#         gammaView.shape = (1, self.ndata)\n",
    "#         print(\"gammaView.shape\", gammaView.shape)\n",
    "        self.p[\"gamma\"] = gamma\n",
    "#         sum_gamma = np.sum(gamma)\n",
    "#         print(\"SUM_GAMMA SHAPE\", sum_gamma.shape)\n",
    "#         print(\"sum gamma\", sum_gamma, \"sum gamma+(1-gamma)\", np.sum(gamma+(1-gamma)))\n",
    "#         print(\"GAMMA TYPE\", type(self.p[\"gamma\"]))\n",
    "#         print(\"GAMMA SHAPE\", self.p[\"gamma\"].shape)\n",
    "        \n",
    "\n",
    "        # ==================== M-STEP ====================\n",
    "\n",
    "        # ========== Component weights w ==========\n",
    "        self.p[\"w\"] = sum(gamma) / self.ndata\n",
    "\n",
    "#         print(\"= W INCOMPLETE LL DEBUG =\")\n",
    "#         newlogl, ill = self.incompletelogl()\n",
    "#         self.debug_logl(self.icll, ill)\n",
    "#         print(\"= END W INCOMPLETE LL DEBUG =\")\n",
    "#         print(\"W LL DEBUG\")\n",
    "#         newlogl, ll = self.logl()\n",
    "#         self.debug_logl(self.cll, ll)\n",
    "        self.assert_logl_increased(\"w\")\n",
    "        \n",
    "        \n",
    "#         # ========== Variables phi ==========\n",
    "        \n",
    "        \n",
    "        # phi_1\n",
    "        blug = eye(self.ndata) * gamma\n",
    "        flup = X.T.dot(blug.dot(X))\n",
    "        sum_gammayx = gamma.T.dot( (Y * self.X.T).T )\n",
    "        self.p[\"phi_1\"] = solve(flup, sum_gammayx)\n",
    "#         self.p[\"phi_1\"] = update_phi_ml(gamma, self.Y, self.X)\n",
    "#         sum_gammayx = gamma.T.dot( (Y * self.X.T).T )\n",
    "#         sum_gammaxx = np.dot( X.T, (gamma * X.T).T )\n",
    "#         self.p[\"phi_1\"] = solve(sum_gammaxx, sum_gammayx)\n",
    "        \n",
    "        self.assert_logl_increased(\"phi_1\")\n",
    "        \n",
    "        \n",
    "        # phi_2\n",
    "        blug = eye(self.ndata) * (1-gamma)\n",
    "        flup = X.T.dot(blug.dot(X))\n",
    "        sum_gammayx = (1-gamma).T.dot( (Y * self.X.T).T )\n",
    "        self.p[\"phi_2\"] = solve(flup, sum_gammayx)\n",
    "#         self.p[\"phi_2\"] = update_phi_ml((1-gamma), self.Y, self.X)\n",
    "#         sum_gammayx = (1-gamma).T.dot(  (Y * self.X.T).T  )\n",
    "#         sum_gammaxx = np.dot( X.T, ((1-gamma) * X.T).T )\n",
    "#         self.p[\"phi_2\"] = solve(sum_gammaxx, sum_gammayx)\n",
    "        \n",
    "        self.assert_logl_increased(\"phi_2\")\n",
    "\n",
    "\n",
    "        # ========== Variances sigma2 ==========\n",
    "        \n",
    "        # sigma2_1\n",
    "#         self.p[\"sigma2_1\"] = update_sigma_ml(self.p[\"phi_1\"], gamma, self.Y, self.X)\n",
    "#         phie = np.sum((self.p[\"phi_1\"] - self.mu_phi0) ** 2)  / self.lbd_phi0\n",
    "        phiX = self.p[\"phi_1\"].dot(self.X.T)\n",
    "        target_err = (self.Y - phiX)**2\n",
    "        err = gamma.dot(target_err)\n",
    "        num = err\n",
    "        den = np.sum(gamma)\n",
    "#         den = 2*self.alpha_s20 + 2.0 + np.sum(gamma) + self.pdata\n",
    "        self.p[\"sigma2_1\"] = num / den\n",
    "#         print(\"phie\", phie.shape, \"phiX.shape\", phiX.shape, \"target_err\", target_err.shape, \"err\", err.shape, \"num\", num.shape, \"den\", den.shape)\n",
    "        if self.p[\"sigma2_1\"] < 0.0:\n",
    "            raise ValueError(\"sigma2_1 < 0.0\")\n",
    "        \n",
    "        # compare ratios\n",
    "#         print(\"phie/P\", phie/self.pdata, \"phie\", phie, \"err/sumGamma\", err/np.sum(gamma), \"err\", err)\n",
    "        \n",
    "        self.assert_logl_increased(\"sigma2_1\")\n",
    "        \n",
    "        # sigma2_2\n",
    "#         self.p[\"sigma2_2\"] = update_sigma_ml(self.p[\"phi_2\"], (1-gamma), self.Y, self.X)\n",
    "#         phie = np.sum((self.p[\"phi_2\"] - self.mu_phi0) ** 2)  / self.lbd_phi0\n",
    "        phiX = self.p[\"phi_2\"].dot(self.X.T)\n",
    "        target_err = (self.Y - phiX)**2\n",
    "        err = (1-gamma).dot(target_err)\n",
    "        num = err\n",
    "        den = np.sum(1-gamma)\n",
    "        self.p[\"sigma2_2\"] = num / den\n",
    "#         print(\"phie\", phie.shape, \"phiX.shape\", phiX.shape, \"target_err\", target_err.shape, \"err\", err.shape, \"num\", num.shape, \"den\", den.shape)\n",
    "        if self.p[\"sigma2_2\"] < 0.0:\n",
    "            raise ValueError(\"sigma2_2 < 0.0\")\n",
    "        \n",
    "        # compare ratios\n",
    "#         print(\"phie/P\", phie/self.pdata, \"phie\", phie, \"err/sum1-Gamma\", err/np.sum(1-gamma), \"err\", err)\n",
    "\n",
    "\n",
    "        self.assert_logl_increased(\"sigma2_2\")\n",
    "#         self.assert_logl_increased(\"sigma2 update\")    \n",
    "        \n",
    "#         print(\"SIGMA LL DEBUG\")\n",
    "#         newlogl, ll = self.logl()\n",
    "#         self.debug_logl(self.cll, ll)\n",
    "        \n",
    "#         # if possible, plot samples, true model and estimated model\n",
    "#         if self.pdata == 1:\n",
    "#             plt.figure(figsize=(20,10))\n",
    "#             plt.scatter(self.X, self.Y, s=20, c='black', label=\"Training data\")\n",
    "#     #         plt.scatter(X_v, Y_v, s=20, c='orange', label=\"Validation data\")\n",
    "#             x = arange(min(self.X)-0.1, max(self.X)+0.1, 0.1)\n",
    "#     #         print_linear_model(x, true_model.get_p()[\"phi\"], \\\n",
    "#     #                 true_model.get_p()[\"sigma2\"], 'red', \"True model\")\n",
    "#     #         print_linear_model(x, model.get_p()[\"phi\"], \\\n",
    "#     #                 model.get_p()[\"sigma2\"], 'blue', \"Predicted model\")\n",
    "#             y = self.p[\"phi_1\"] * x\n",
    "#             color = 'red'\n",
    "#             plt.plot(x, y, color, label=\"component1\")\n",
    "#             plt.fill_between(x, y + 1.96 * sqrt(self.p[\"sigma2_1\"]), y - 1.96 * sqrt(self.p[\"sigma2_1\"]), alpha=0.25, facecolor=color, interpolate=True)\n",
    "            \n",
    "#             y = self.p[\"phi_2\"] * x\n",
    "#             color = 'blue'\n",
    "#             plt.plot(x, y, color, label=\"component2\")\n",
    "#             plt.fill_between(x, y + 1.96 * sqrt(self.p[\"sigma2_2\"]), y - 1.96 * sqrt(self.p[\"sigma2_2\"]), alpha=0.25, facecolor=color, interpolate=True)\n",
    "\n",
    "#             plt.legend(loc=1)\n",
    "#             plt.xlim(min(x), max(x))\n",
    "#             plt.xlabel(\"x\")\n",
    "#             plt.ylabel(\"y\")\n",
    "#             plt.show()\n",
    "#             input(\"Press Enter to continue...\")\n",
    "        \n",
    "        #print(\"w\", self.p[\"w\"], \"phi_1\", self.p[\"phi_1\"], \"phi_2\", self.p[\"phi_2\"], \"s2_1\", self.p[\"sigma2_1\"], \"s2_2\", self.p[\"sigma2_2\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EM_algo_MM(EM_algo):\n",
    "    \"\"\"\n",
    "        A mixture of two linear models.\n",
    "    \"\"\"\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            Reset priors and draw parameter estimates from prior.\n",
    "        \"\"\"\n",
    "        # priors\n",
    "        self.alpha_w0       = self.h[\"alpha_w0\"]\n",
    "        self.beta_w0        = self.h[\"beta_w0\"]\n",
    "\n",
    "        # Same priors for phi1 and phi2, s2_1, s2_2, don't bother to copy vars twice\n",
    "        # i.e. alpha_s2_1_0 = alpha_s2_2_0 = alpha_s20\n",
    "        self.lbd_phi0       = self.h[\"lbd_phi0\"]\n",
    "        self.alpha_s20      = self.h[\"alpha_s20\"]\n",
    "        self.beta_s20       = self.h[\"beta_s20\"]\n",
    "        self.sigma_phi0     = eye(self.pdata) * self.h[\"lbd_phi0\"]\n",
    "        self.sigma_phi0_inv = eye(self.pdata) / self.h[\"lbd_phi0\"]\n",
    "        self.mu_phi0        = ones(self.pdata) * self.h[\"mu_phi0\"]\n",
    "        \n",
    "        # Precalculations:\n",
    "#         self.w_gamma_ln_multiplier  = gammaln(self.alpha_w0 + self.beta_w0) - gammaln(self.alpha_w0) - gammaln(self.beta_w0)\n",
    "        self.w_gamma_ln_multiplier  = log(gamma(self.alpha_w0 + self.beta_w0)) - log(gammaln(self.alpha_w0)) - log(gammaln(self.beta_w0))\n",
    "#         self.w_gamma_ln_multiplier -= gammaln(self.alpha_w0)\n",
    "#         self.w_gamma_ln_multiplier -= gammaln(self.beta_w0)\n",
    "        \n",
    "        \n",
    "        # initial parameter estimates drawn from prior\n",
    "        self.p             = dict()\n",
    "        # Weights\n",
    "        self.p[\"w\"]        = beta(self.alpha_w0, self.beta_w0)\n",
    "        # Responsibilities (TODO: do we need this here?)\n",
    "        self.p[\"gamma\"]    = binomial(1, self.p[\"w\"], self.ndata)\n",
    "#         print(\"INIT GAMMA TYPE\", type(self.p[\"gamma\"]))\n",
    "#         print(\"INIT GAMMA SHAPE\", self.p[\"gamma\"].shape)\n",
    "        # Component 1\n",
    "        self.p[\"sigma2_1\"] = 1.0 / gamma(self.alpha_s20, 1.0 / self.beta_s20) # inverse gamma\n",
    "        self.p[\"phi_1\"]    = mvnormal(self.mu_phi0, self.p[\"sigma2_1\"] * self.sigma_phi0)\n",
    "#         print(\"INIT PHI1 SHAPE\", self.p[\"phi_1\"].shape)\n",
    "        # Component 2\n",
    "        self.p[\"sigma2_2\"] = 1.0 / gamma(self.alpha_s20, 1.0 / self.beta_s20) # inverse gamma\n",
    "        self.p[\"phi_2\"]    = mvnormal(self.mu_phi0, self.p[\"sigma2_2\"] * self.sigma_phi0)\n",
    "        \n",
    "        if not self.X is None and not self.Y is None:\n",
    "            self.current_ilogl, self.icll = self.incompletelogl()\n",
    "        \n",
    "#         print(\"START w\", self.p[\"w\"])\n",
    "#         print(\"START phi_1\", self.p[\"phi_1\"])\n",
    "#         print(\"START sigma2_1\", self.p[\"sigma2_1\"])\n",
    "#         print(\"START phi_2\", self.p[\"phi_2\"])\n",
    "#         print(\"START sigma2_2\", self.p[\"sigma2_2\"])\n",
    "\n",
    "\n",
    "    def draw(self, item):\n",
    "        \"\"\"\n",
    "            Draw a data sample from the current predictive distribution.\n",
    "            Returns the y-value and z-value\n",
    "        \"\"\"\n",
    "        mean1 = float(item.dot(self.p[\"phi_1\"]))\n",
    "        std1  = sqrt(self.p[\"sigma2_1\"])\n",
    "        mean2 = float(item.dot(self.p[\"phi_2\"]))\n",
    "        std2  = sqrt(self.p[\"sigma2_2\"])\n",
    "        \n",
    "        if np.random.rand() < self.p[\"w\"]:\n",
    "            return normal(mean1, std1), 1\n",
    "        else:\n",
    "            return normal(mean2, std2), 2\n",
    "\n",
    "\n",
    "    def logl(self):\n",
    "        \"\"\"\n",
    "            Calculates the full log likelihood for this model.\n",
    "            Returns the logl (and the values of each term for debugging purposes)\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.incompletelogl()\n",
    "        \n",
    "#         phie  = self.p[\"phi\"] - self.mu_phi0\n",
    "#         err   = (self.X.dot(self.p[\"phi\"]) - self.Y) ** 2\n",
    "#         # p(y)\n",
    "#         ll[0] = - 0.5 * log(2 * pi * self.p[\"sigma2\"]) * self.ndata\n",
    "#         ll[1] = sum(- 0.5 * err / self.p[\"sigma2\"])\n",
    "#         # p(phi)\n",
    "#         ll[2] = - 0.5 * log(2 * pi * self.lbd_phi0 * self.p[\"sigma2\"]) * self.pdata\n",
    "#         ll[3] = - 0.5 * phie.T.dot(phie) / (self.lbd_phi0 * self.p[\"sigma2\"])\n",
    "#         # p(sigma2)\n",
    "#         ll[4] = self.alpha_s20 * log(self.beta_s20)\n",
    "#         ll[5] = - gammaln(self.alpha_s20)\n",
    "#         ll[6] = - (self.alpha_s20 + 1.0) * log(self.p[\"sigma2\"])\n",
    "#         ll[7] = - self.beta_s20 / self.p[\"sigma2\"]\n",
    "        \n",
    "        ll         = zeros(20)\n",
    "        phi_1_diff = self.p[\"phi_1\"] - self.mu_phi0\n",
    "#         print(\"phi_1_diff\", phi_1_diff.shape)\n",
    "        phi_2_diff = self.p[\"phi_2\"] - self.mu_phi0\n",
    "        phi_1_err  = phi_1_diff.T.dot(phi_1_diff)\n",
    "#         print(\"phi_1_err\", phi_1_err.shape)\n",
    "        phi_2_err  = phi_2_diff.T.dot(phi_2_diff)\n",
    "#         err_1      = (self.X.dot(self.p[\"phi_1\"]) - self.Y) ** 2\n",
    "#         err_2      = (self.X.dot(self.p[\"phi_2\"]) - self.Y) ** 2\n",
    "#         print(\"phi1\", self.p[\"phi_1\"].shape)\n",
    "        err_1      = (self.Y - self.X.dot(self.p[\"phi_1\"])) ** 2\n",
    "#         print(\"err\", err_1.shape)\n",
    "#         print(\"self.Y\", self.Y.shape, Y.shape)\n",
    "#         print(\"self.X.dot(self.p[phi_1])\", self.X.dot(self.p[\"phi_1\"]).shape)\n",
    "        err_2      = (self.Y - self.X.dot(self.p[\"phi_2\"])) ** 2\n",
    "        \n",
    "        # Responsibilities\n",
    "#         propto_gamma1 =      self.p[\"w\"]  * norm.pdf(self.Y, self.X.dot(self.p[\"phi_1\"]), sqrt(self.p[\"sigma2_1\"]))\n",
    "#         propto_gamma2 = (1 - self.p[\"w\"]) * norm.pdf(self.Y, self.X.dot(self.p[\"phi_2\"]), sqrt(self.p[\"sigma2_2\"]))\n",
    "#         gamma = propto_gamma1 / (propto_gamma1 + propto_gamma2)\n",
    "        gamma = self.p[\"gamma\"]\n",
    "        \n",
    "        ### posterior factorizes p(y,z,w,phi,sigma) = p(y)p(z)p(w)p(phi)p(sigma)\n",
    "        \n",
    "        ### p(y)\n",
    "#         ll[0] = self.p[\"w\"]       * (-0.5 * log(2 * pi * self.p[\"sigma2_1\"]) * self.ndata)\n",
    "#         ll[1] = self.p[\"w\"]       * np.sum(- 0.5 * err_1 / self.p[\"sigma2_1\"])\n",
    "#         ll[2] = (1 - self.p[\"w\"]) * (-0.5 * log(2 * pi * self.p[\"sigma2_2\"]) * self.ndata)\n",
    "#         ll[3] = (1 - self.p[\"w\"]) * np.sum(- 0.5 * err_2 / self.p[\"sigma2_2\"])\n",
    "\n",
    "#         wN1 =    gamma  * norm.pdf(self.Y, self.X.dot(self.p[\"phi_1\"]), sqrt(self.p[\"sigma2_1\"]))\n",
    "#         wN2 = (1-gamma) * norm.pdf(self.Y, self.X.dot(self.p[\"phi_2\"]), sqrt(self.p[\"sigma2_2\"]))\n",
    "#         ll[0] = np.sum( log( wN1 + wN2 ) )\n",
    "\n",
    "#         ll[0] =       gamma.dot(-0.5 * log(2 * pi * self.p[\"sigma2_1\"]) -0.5 * err_1 / self.p[\"sigma2_1\"])\n",
    "#         ll[1] = 0\n",
    "#         ll[2] = (1 - gamma).dot(-0.5 * log(2 * pi * self.p[\"sigma2_2\"]) -0.5 * err_2 / self.p[\"sigma2_2\"])\n",
    "#         ll[3] = 0\n",
    "\n",
    "        ll[0] = -0.5 * log(2 * pi * self.p[\"sigma2_1\"]) * np.sum(gamma)\n",
    "        ll[1] = gamma.dot(-0.5 * err_1 / self.p[\"sigma2_1\"])\n",
    "        ll[2] = -0.5 * log(2 * pi * self.p[\"sigma2_2\"]) * np.sum(1 - gamma)\n",
    "        ll[3] = (1 - gamma).dot(-0.5 * err_2 / self.p[\"sigma2_2\"])\n",
    "\n",
    "#         ll[0] = log(self.p[\"w\"]) * np.sum(gamma) - 0.5 * log(2 * pi * self.p[\"sigma2_1\"]) * np.sum(gamma)\n",
    "#         ll[1] = gamma.dot(-0.5 * err_1 / self.p[\"sigma2_1\"])\n",
    "#         ll[2] = log(1-self.p[\"w\"]) * np.sum(1-gamma) - 0.5 * log(2 * pi * self.p[\"sigma2_2\"]) * np.sum(1 - gamma)\n",
    "#         ll[3] = (1 - gamma).dot(-0.5 * err_2 / self.p[\"sigma2_2\"])\n",
    " \n",
    "        \n",
    "        ### p(z)\n",
    "#         ll[4] = np.sum((gamma * log(self.p[\"w\"])) + ((1 - gamma) * log(1 - self.p[\"w\"])))\n",
    "        \n",
    "        ### p(w)\n",
    "        ll[5] = self.w_gamma_ln_multiplier\n",
    "        ll[6] = (self.alpha_w0 - 1) * self.p[\"w\"]\n",
    "        ll[7] = (self.beta_w0  - 1) * (1 - self.p[\"w\"])\n",
    "        \n",
    "        ### p(phi)\n",
    "        # phi_1\n",
    "        ll[8]  = - 0.5 * log(2 * pi * self.lbd_phi0 * self.p[\"sigma2_1\"]) * self.pdata\n",
    "        ll[9]  = - 0.5 * phi_1_err / (self.lbd_phi0 * self.p[\"sigma2_1\"])\n",
    "        # phi_2\n",
    "        ll[10] = - 0.5 * log(2 * pi * self.lbd_phi0 * self.p[\"sigma2_2\"]) * self.pdata\n",
    "        ll[11] = - 0.5 * phi_2_err / (self.lbd_phi0 * self.p[\"sigma2_2\"])\n",
    "        \n",
    "        ### p(sigma2)\n",
    "        # sigma2_1\n",
    "        ll[12] = self.alpha_s20 * log(self.beta_s20)\n",
    "        ll[13] = - gammaln(self.alpha_s20)\n",
    "        ll[14] = - (self.alpha_s20 + 1.0) * log(self.p[\"sigma2_1\"])\n",
    "        ll[15] = - self.beta_s20 / self.p[\"sigma2_1\"]\n",
    "        # sigma2_2\n",
    "        ll[16] = self.alpha_s20 * log(self.beta_s20)\n",
    "        ll[17] = - gammaln(self.alpha_s20)\n",
    "        ll[18] = - (self.alpha_s20 + 1.0) * log(self.p[\"sigma2_2\"])\n",
    "        ll[19] = - self.beta_s20 / self.p[\"sigma2_2\"]\n",
    "        \n",
    "        return np.sum(ll), ll\n",
    "\n",
    "\n",
    "    def incompletelogl(self):\n",
    "        \"\"\"\n",
    "            Calculates the incomplete data log likelihood for this model.\n",
    "            Returns the logl (and the values of each term for debugging purposes)\n",
    "        \"\"\"\n",
    "        ll         = zeros(20)\n",
    "        phi_1_diff = self.p[\"phi_1\"] - self.mu_phi0\n",
    "        phi_2_diff = self.p[\"phi_2\"] - self.mu_phi0\n",
    "        phi_1_err  = phi_1_diff.T.dot(phi_1_diff)\n",
    "        phi_2_err  = phi_2_diff.T.dot(phi_2_diff)\n",
    "#         err_1      = (self.X.dot(self.p[\"phi_1\"]) - self.Y) ** 2\n",
    "#         err_2      = (self.X.dot(self.p[\"phi_2\"]) - self.Y) ** 2\n",
    "        \n",
    "        ### p(y)\n",
    "        N1 = norm.pdf(self.Y, self.X.dot(self.p[\"phi_1\"]), sqrt(self.p[\"sigma2_1\"]))\n",
    "        N2 = norm.pdf(self.Y, self.X.dot(self.p[\"phi_2\"]), sqrt(self.p[\"sigma2_2\"]))\n",
    "        ll[1] = np.sum( np.log( self.p[\"w\"]*N1 + (1-self.p[\"w\"])*N2 ) )\n",
    "        \n",
    "#         wN1 =    self.p[\"w\"]  * norm.pdf(self.Y, self.X.dot(self.p[\"phi_1\"]), sqrt(self.p[\"sigma2_1\"]))\n",
    "#         wN2 = (1-self.p[\"w\"]) * norm.pdf(self.Y, self.X.dot(self.p[\"phi_2\"]), sqrt(self.p[\"sigma2_2\"]))\n",
    "#         ll[0] = np.sum( log( wN1 + wN2 ) )\n",
    "        \n",
    "#         ll[0] = self.p[\"w\"]       * (-0.5 * log(2 * pi * self.p[\"sigma2_1\"]) * self.ndata)\n",
    "#         ll[1] = self.p[\"w\"]       * np.sum(- 0.5 * err_1 / self.p[\"sigma2_1\"])\n",
    "#         ll[2] = (1 - self.p[\"w\"]) * (-0.5 * log(2 * pi * self.p[\"sigma2_2\"]) * self.ndata)\n",
    "#         ll[3] = (1 - self.p[\"w\"]) * np.sum(- 0.5 * err_2 / self.p[\"sigma2_2\"])\n",
    " \n",
    "        ### p(z)\n",
    "#         gamma = self.p[\"gamma\"]\n",
    "#         ll[4] = np.sum((gamma * log(self.p[\"w\"])) + ((1 - gamma) * log(1 - self.p[\"w\"])))\n",
    "        ll[4] = 0\n",
    "        \n",
    "        ### p(w)\n",
    "        ll[5] = self.w_gamma_ln_multiplier\n",
    "        ll[6] = (self.alpha_w0 - 1) * self.p[\"w\"]\n",
    "        ll[7] = (self.beta_w0  - 1) * (1 - self.p[\"w\"])\n",
    "        \n",
    "        ### p(phi)\n",
    "        # phi_1\n",
    "        ll[8]  = - 0.5 * log(2 * pi * self.lbd_phi0 * self.p[\"sigma2_1\"]) * self.pdata\n",
    "        ll[9]  = - 0.5 * phi_1_err / (self.lbd_phi0 * self.p[\"sigma2_1\"])\n",
    "        # phi_2\n",
    "        ll[10] = - 0.5 * log(2 * pi * self.lbd_phi0 * self.p[\"sigma2_2\"]) * self.pdata\n",
    "        ll[11] = - 0.5 * phi_2_err / (self.lbd_phi0 * self.p[\"sigma2_2\"])\n",
    "        \n",
    "        ### p(sigma2)\n",
    "        # sigma2_1\n",
    "        ll[12] = self.alpha_s20 * log(self.beta_s20)\n",
    "        ll[13] = - gammaln(self.alpha_s20)\n",
    "        ll[14] = - (self.alpha_s20 + 1.0) * log(self.p[\"sigma2_1\"])\n",
    "        ll[15] = - self.beta_s20 / self.p[\"sigma2_1\"]\n",
    "        # sigma2_2\n",
    "        ll[16] = self.alpha_s20 * log(self.beta_s20)\n",
    "        ll[17] = - gammaln(self.alpha_s20)\n",
    "        ll[18] = - (self.alpha_s20 + 1.0) * log(self.p[\"sigma2_2\"])\n",
    "        ll[19] = - self.beta_s20 / self.p[\"sigma2_2\"]\n",
    "        \n",
    "        return np.sum(ll), ll\n",
    "\n",
    "\n",
    "    def EM_iter(self):\n",
    "        \"\"\"\n",
    "            Executes a single round of EM updates for this model.\n",
    "\n",
    "            Has checks to make sure that updates increase logl and\n",
    "            that parameter values stay in sensible limits.\n",
    "        \"\"\"\n",
    "        \n",
    "#         Y = self.Y.view()\n",
    "#         Y.shape = (self.ndata, 1) # set Y view shape\n",
    "\n",
    "        # ==================== E-STEP ====================\n",
    "\n",
    "        # ========== Responsibilities gamma ==========        \n",
    "        # norm.pdf works on a vector, returning probability for each separately\n",
    "#         propto_gamma1_x =      self.p[\"w\"]  * norm.pdf(self.Y, self.X.dot(self.p[\"phi_1\"]), sqrt(self.p[\"sigma2_1\"]))\n",
    "#         propto_gamma2_x = (1 - self.p[\"w\"]) * norm.pdf(self.Y, self.X.dot(self.p[\"phi_2\"]), sqrt(self.p[\"sigma2_2\"]))\n",
    "        \n",
    "        propto_gamma1 = np.zeros(self.ndata)\n",
    "        for t in range(self.ndata):\n",
    "            propto_gamma1[t] = self.p[\"w\"] * 1/(sqrt(2*pi*self.p[\"sigma2_1\"])) * np.exp(-0.5 * ((self.Y[t] - self.p[\"phi_1\"].dot(X[t].T))**2)/self.p[\"sigma2_1\"])\n",
    "        propto_gamma2 = np.zeros(self.ndata)\n",
    "        for t in range(self.ndata):\n",
    "            propto_gamma2[t] = (1-self.p[\"w\"]) * 1/(sqrt(2*pi*self.p[\"sigma2_2\"])) * np.exp(-0.5 * ((self.Y[t] - self.p[\"phi_2\"].dot(X[t].T))**2)/self.p[\"sigma2_2\"])\n",
    "        \n",
    "#         print(\"propto_gamma1\", propto_gamma1.shape, \"propto_gamma2\", propto_gamma2.shape)\n",
    "#         print(\"propto_gamma1_x\", propto_gamma1_x.shape, \"propto_gamma2_x\", propto_gamma2_x.shape)\n",
    "#         print(np.sum(propto_gamma1 - propto_gamma1_x), np.sum(propto_gamma2 - propto_gamma2_x))\n",
    "#         print(\"n\", propto_gamma1 > 1.0)\n",
    "#         print(\"x\", propto_gamma1_x > 1.0)\n",
    "#         print(propto_gamma1)\n",
    "#         print(propto_gamma1_x)\n",
    "        # elementwise, works because numpy\n",
    "        gamma = propto_gamma1 / (propto_gamma1 + propto_gamma2)\n",
    "#         print(\"gamma\", gamma.shape)\n",
    "#         gammaView = gamma.view()\n",
    "#         gammaView.shape = (1, self.ndata)\n",
    "#         print(\"gammaView.shape\", gammaView.shape)\n",
    "        self.p[\"gamma\"] = gamma\n",
    "        sum_gamma = np.sum(gamma)\n",
    "#         print(\"sum gamma\", sum_gamma, \"sum gamma+(1-gamma)\", np.sum(gamma+(1-gamma)))\n",
    "#         print(\"GAMMA TYPE\", type(self.p[\"gamma\"]))\n",
    "#         print(\"GAMMA SHAPE\", self.p[\"gamma\"].shape)\n",
    "        \n",
    "\n",
    "        # ==================== M-STEP ====================\n",
    "\n",
    "        # ========== Component weights w ==========\n",
    "        num = 2*sum_gamma + self.alpha_w0 - 1\n",
    "        den = 2*self.ndata + self.alpha_w0 + self.beta_w0 - 2\n",
    "#         num = sum_gamma + self.alpha_w0 - 1\n",
    "#         den = self.ndata + self.alpha_w0 + self.beta_w0 - 2\n",
    "#         num = sum_gamma\n",
    "#         den = self.ndata\n",
    "        self.p[\"w\"] = num / den\n",
    "\n",
    "#         print(\"= W INCOMPLETE LL DEBUG =\")\n",
    "#         newlogl, ill = self.incompletelogl()\n",
    "#         self.debug_logl(self.icll, ill)\n",
    "#         print(\"= END W INCOMPLETE LL DEBUG =\")\n",
    "#         print(\"W LL DEBUG\")\n",
    "#         newlogl, ll = self.logl()\n",
    "#         self.debug_logl(self.cll, ll)\n",
    "        self.assert_logl_increased(\"w\")\n",
    "    \n",
    "    \n",
    "        # ========== Variances sigma2 ==========\n",
    "        # phi_1 and phi_2 still have the previous value, i.e. from step s, we are calculating sigma for step s+1\n",
    "        \n",
    "        # sigma2_1\n",
    "        phie = np.sum((self.p[\"phi_1\"] - self.mu_phi0) ** 2)  / self.lbd_phi0\n",
    "        phiX = self.p[\"phi_1\"].dot(self.X.T)\n",
    "        target_err = (self.Y - phiX)**2\n",
    "        err = gamma.dot(target_err)\n",
    "        num = 2*self.beta_s20 + err + phie\n",
    "        den = 2*self.alpha_s20 + 2.0 + np.sum(gamma) + self.pdata\n",
    "        self.p[\"sigma2_1\"] = num / den\n",
    "#         print(\"phie\", phie.shape, \"phiX.shape\", phiX.shape, \"target_err\", target_err.shape, \"err\", err.shape, \"num\", num.shape, \"den\", den.shape)\n",
    "        if self.p[\"sigma2_1\"] < 0.0:\n",
    "            raise ValueError(\"sigma2_1 < 0.0\")\n",
    "        \n",
    "        # compare ratios\n",
    "#         print(\"phie/P\", phie/self.pdata, \"phie\", phie, \"err/sumGamma\", err/np.sum(gamma), \"err\", err)\n",
    "        \n",
    "#         self.assert_logl_increased(\"sigma2_1\")\n",
    "        \n",
    "        # sigma2_2\n",
    "        phie = np.sum((self.p[\"phi_2\"] - self.mu_phi0) ** 2)  / self.lbd_phi0\n",
    "        phiX = self.p[\"phi_2\"].dot(self.X.T)\n",
    "        target_err = (self.Y - phiX)**2\n",
    "        err = (1-gamma).dot(target_err)\n",
    "        num = 2*self.beta_s20 + err + phie\n",
    "        den = 2*self.alpha_s20 + 2.0 + np.sum(1-gamma) + self.pdata\n",
    "        self.p[\"sigma2_2\"] = num / den\n",
    "#         print(\"phie\", phie.shape, \"phiX.shape\", phiX.shape, \"target_err\", target_err.shape, \"err\", err.shape, \"num\", num.shape, \"den\", den.shape)\n",
    "        if self.p[\"sigma2_2\"] < 0.0:\n",
    "            raise ValueError(\"sigma2_2 < 0.0\")\n",
    "        \n",
    "        # compare ratios\n",
    "#         print(\"phie/P\", phie/self.pdata, \"phie\", phie, \"err/sum1-Gamma\", err/np.sum(1-gamma), \"err\", err)\n",
    "\n",
    "\n",
    "#         self.assert_logl_increased(\"sigma2_2\")\n",
    "#         self.assert_logl_increased(\"sigma2 update\")    \n",
    "        \n",
    "#         print(\"SIGMA LL DEBUG\")\n",
    "#         newlogl, ll = self.logl()\n",
    "#         self.debug_logl(self.cll, ll)\n",
    "        \n",
    "        \n",
    "#         # ========== Variables phi ==========\n",
    "        \n",
    "        \n",
    "        # phi_1\n",
    "        sum_gammayx = gamma.T.dot( (Y * self.X.T).T )\n",
    "#         sum_gammayx2 = gamma.T.dot(Y * self.X).T\n",
    "#         gammaX = gammaView.T * X\n",
    "#         print(\"GAMMAX SHAPE\", gammaX.shape, \"Y shape\", Y.shape)\n",
    "#         sum_gammayx3 = Y.T.dot(gammaX)\n",
    "#         sum_gammayx4 = Y.T.dot(gammaX).T\n",
    "#         print(\"CHECK1\", sum_gammayx, sum_gammayx3, sum_gammayx3-sum_gammayx)\n",
    "#         print(\"CHECK2\", sum_gammayx.shape, sum_gammayx2.shape, sum_gammayx3.shape, sum_gammayx4.shape)\n",
    "        # NEW\n",
    "#         sum_gammaxx = np.dot( X.T, (gammaView.T * X) ) # WORKING\n",
    "        sum_gammaxx = np.dot( X.T, (gamma * X.T).T )\n",
    "#         sum_gammaxx = np.dot( X.T, (gammarep.T * X) )\n",
    "        \n",
    "#         sum_gammaxx = np.zeros([self.pdata,self.pdata])\n",
    "#         print(\"gamma\", gamma.shape)\n",
    "#         for t in range(0,self.ndata):\n",
    "#             sum_gammaxx += gamma[t] * np.dot(X[t].T, X[t])\n",
    "# #         sum_gammaxx = gamma.T.dot((self.X * self.X))\n",
    "        # END NEW\n",
    "#         sigma_phi_inv = self.sigma_phi0_inv + sum_gammaxx\n",
    "#         print(\"self.sigma_phi0_inv\", self.sigma_phi0_inv.shape, \"sigma_phi_inv\", sigma_phi_inv.shape)\n",
    "#         print(\"sum_gammayx, sum_gammaxx SHAPES\", sum_gammayx.shape, sum_gammaxx.shape)\n",
    "        sigma_mu        = self.sigma_phi0_inv.dot(self.mu_phi0)\n",
    "        sigma_phi_inv   = self.sigma_phi0_inv + sum_gammaxx\n",
    "        self.p[\"phi_1\"] = solve(sigma_phi_inv, sigma_mu + sum_gammayx)\n",
    "#         print(\"TEST 1\", solve(sigma_phi_inv, sigma_mu + sum_gammayx), \"TEST2\", solve(sigma_phi_inv, sigma_mu + sum_gammayx2))\n",
    "#         print(\"sum_gammaxx\", sum_gammaxx.shape, \"sum_gammaxy\", sum_gammayx.shape, \"sigma_mu\", sigma_mu.shape, \"sigma_phi_inv\", sigma_phi_inv.shape)\n",
    "#         print(\"phi_1\", self.p[\"phi_1\"])\n",
    "        \n",
    "#         self.assert_logl_increased(\"phi_1\")\n",
    "        \n",
    "        \n",
    "        # phi_2\n",
    "        sum_gammayx = (1-gamma).T.dot(  (Y * self.X.T).T  )\n",
    "#         sum_gammayx = Y.T.dot((1-gammaView).T * X)\n",
    "        # NEW\n",
    "        sum_gammaxx = np.dot( X.T, ((1-gamma) * X.T).T )\n",
    "#         sum_gammaxx = np.dot( X.T, (one_minus_gammarep.T * X) )\n",
    "        \n",
    "#         sum_gammaxx = np.zeros([self.pdata,self.pdata])\n",
    "#         for t in range(0,self.ndata):\n",
    "#             sum_gammaxx += (1-gamma[t]) * np.dot(X[t].T, X[t])\n",
    "#         # END NEW\n",
    "# #         sum_gammaxx = (1-gamma).T.dot((self.X * self.X))\n",
    "#         print(\"self.sigma_phi0_inv\", self.sigma_phi0_inv.shape, \"sigma_phi_inv\", sigma_phi_inv.shape)\n",
    "#         print(\"sum_gammayx, sum_gammaxx SHAPES\", sum_gammayx.shape, sum_gammaxx.shape)\n",
    "        sigma_mu        = self.sigma_phi0_inv.dot(self.mu_phi0)\n",
    "        sigma_phi_inv   = self.sigma_phi0_inv + sum_gammaxx\n",
    "        self.p[\"phi_2\"] = solve(sigma_phi_inv, sigma_mu + sum_gammayx)\n",
    "#         print(\"sum_gammaxx\", sum_gammaxx.shape, \"sum_gammaxy\", sum_gammayx.shape, \"sigma_mu\", sigma_mu.shape, \"sigma_phi_inv\", sigma_phi_inv.shape)\n",
    "#         print(\"phi_2\", self.p[\"phi_2\"])\n",
    "        \n",
    "#         print(\"PHI LL DEBUG\")\n",
    "#         newlogl, ll = self.logl()\n",
    "#         self.debug_logl(self.cll, ll)\n",
    "        self.assert_logl_increased(\"phi_2\")\n",
    "\n",
    "\n",
    "#         # ========== Variances sigma2 ==========\n",
    "        \n",
    "#         # sigma2_1\n",
    "#         phie = np.sum((self.p[\"phi_1\"] - self.mu_phi0) ** 2)  / self.lbd_phi0\n",
    "#         phiX = self.p[\"phi_1\"].dot(self.X.T)\n",
    "#         target_err = (self.Y - phiX)**2\n",
    "#         err = gamma.dot(target_err)\n",
    "#         num = 2*self.beta_s20 + err + phie\n",
    "#         den = 2*self.alpha_s20 + 2.0 + np.sum(gamma) + self.pdata\n",
    "#         self.p[\"sigma2_1\"] = num / den\n",
    "# #         print(\"phie\", phie.shape, \"phiX.shape\", phiX.shape, \"target_err\", target_err.shape, \"err\", err.shape, \"num\", num.shape, \"den\", den.shape)\n",
    "#         if self.p[\"sigma2_1\"] < 0.0:\n",
    "#             raise ValueError(\"sigma2_1 < 0.0\")\n",
    "        \n",
    "#         # compare ratios\n",
    "# #         print(\"phie/P\", phie/self.pdata, \"phie\", phie, \"err/sumGamma\", err/np.sum(gamma), \"err\", err)\n",
    "        \n",
    "#         self.assert_logl_increased(\"sigma2_1\")\n",
    "        \n",
    "#         # sigma2_2\n",
    "#         phie = np.sum((self.p[\"phi_2\"] - self.mu_phi0) ** 2)  / self.lbd_phi0\n",
    "#         phiX = self.p[\"phi_2\"].dot(self.X.T)\n",
    "#         target_err = (self.Y - phiX)**2\n",
    "#         err = (1-gamma).dot(target_err)\n",
    "#         num = 2*self.beta_s20 + err + phie\n",
    "#         den = 2*self.alpha_s20 + 2.0 + np.sum(1-gamma) + self.pdata\n",
    "#         self.p[\"sigma2_2\"] = num / den\n",
    "# #         print(\"phie\", phie.shape, \"phiX.shape\", phiX.shape, \"target_err\", target_err.shape, \"err\", err.shape, \"num\", num.shape, \"den\", den.shape)\n",
    "#         if self.p[\"sigma2_2\"] < 0.0:\n",
    "#             raise ValueError(\"sigma2_2 < 0.0\")\n",
    "        \n",
    "#         # compare ratios\n",
    "# #         print(\"phie/P\", phie/self.pdata, \"phie\", phie, \"err/sum1-Gamma\", err/np.sum(1-gamma), \"err\", err)\n",
    "\n",
    "\n",
    "#         self.assert_logl_increased(\"sigma2_2\")\n",
    "# #         self.assert_logl_increased(\"sigma2 update\")    \n",
    "        \n",
    "# #         print(\"SIGMA LL DEBUG\")\n",
    "# #         newlogl, ll = self.logl()\n",
    "# #         self.debug_logl(self.cll, ll)\n",
    "        \n",
    "#         # if possible, plot samples, true model and estimated model\n",
    "#         if self.pdata == 1:\n",
    "#             plt.figure(figsize=(20,10))\n",
    "#             plt.scatter(self.X, self.Y, s=20, c='black', label=\"Training data\")\n",
    "#     #         plt.scatter(X_v, Y_v, s=20, c='orange', label=\"Validation data\")\n",
    "#             x = arange(min(self.X)-0.1, max(self.X)+0.1, 0.1)\n",
    "#     #         print_linear_model(x, true_model.get_p()[\"phi\"], \\\n",
    "#     #                 true_model.get_p()[\"sigma2\"], 'red', \"True model\")\n",
    "#     #         print_linear_model(x, model.get_p()[\"phi\"], \\\n",
    "#     #                 model.get_p()[\"sigma2\"], 'blue', \"Predicted model\")\n",
    "#             y = self.p[\"phi_1\"] * x\n",
    "#             color = 'red'\n",
    "#             plt.plot(x, y, color, label=\"component1\")\n",
    "#             plt.fill_between(x, y + 1.96 * sqrt(self.p[\"sigma2_1\"]), y - 1.96 * sqrt(self.p[\"sigma2_1\"]), alpha=0.25, facecolor=color, interpolate=True)\n",
    "            \n",
    "#             y = self.p[\"phi_2\"] * x\n",
    "#             color = 'blue'\n",
    "#             plt.plot(x, y, color, label=\"component2\")\n",
    "#             plt.fill_between(x, y + 1.96 * sqrt(self.p[\"sigma2_2\"]), y - 1.96 * sqrt(self.p[\"sigma2_2\"]), alpha=0.25, facecolor=color, interpolate=True)\n",
    "\n",
    "#             plt.legend(loc=1)\n",
    "#             plt.xlim(min(x), max(x))\n",
    "#             plt.xlabel(\"x\")\n",
    "#             plt.ylabel(\"y\")\n",
    "#             plt.show()\n",
    "#             input(\"Press Enter to continue...\")\n",
    "        \n",
    "        #print(\"w\", self.p[\"w\"], \"phi_1\", self.p[\"phi_1\"], \"phi_2\", self.p[\"phi_2\"], \"s2_1\", self.p[\"sigma2_1\"], \"s2_2\", self.p[\"sigma2_2\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit (logl -34.68) after 73 iterations (alim reached)\n",
      "\n",
      "MAP estimate of true model parameters:\n",
      "phi_2 = [-0.74280749  0.06516523  0.46845568 -0.73660718  0.13075443  0.08773167\n",
      "  0.55690992 -0.19581462  0.37689696 -0.39361115 -0.33104239 -0.13912593\n",
      " -0.46139462  0.01766988  0.15080123 -0.24216459 -0.48370614 -0.48219254\n",
      "  0.10761102 -0.77278163 -0.21155728  0.08172795 -0.2304907   0.06264725\n",
      "  0.6741262 ]\n",
      "sigma2_1 = 0.0709366273502\n",
      "sigma2_2 = 0.118233451188\n",
      "w = 0.518835202255\n",
      "phi_1 = [ 0.23215152 -0.18087002 -0.05732405  0.36762954 -0.02943917  0.33959919\n",
      " -0.09060954 -0.39791021  0.12459054 -0.23169578  0.0579912  -0.03857879\n",
      "  0.15484226  0.06988388  0.53419598  0.06540299  0.29678898 -0.06121358\n",
      "  0.2928115   0.41234414 -0.09940484  0.33034907  0.29313652 -0.61048573\n",
      "  0.18847073]\n",
      "gamma = [  6.31862084e-01   9.99978234e-01   1.53922674e-40   3.67770600e-02\n",
      "   2.21037919e-27   5.46054985e-01   1.34640009e-11   1.00000000e+00\n",
      "   2.75610021e-15   3.00240701e-05   9.99905848e-01   3.13588638e-24\n",
      "   2.72003291e-04   1.00000000e+00   1.00000000e+00   1.00000000e+00\n",
      "   2.36742489e-02   1.54457175e-12   1.00000000e+00   5.81795772e-01\n",
      "   9.99999986e-01   4.46355360e-05   5.46265039e-01   1.00000000e+00\n",
      "   6.11766269e-01   5.78987154e-01   1.17942004e-17   1.00000000e+00\n",
      "   6.50090427e-01   9.19443618e-07   6.68797648e-01   1.04485342e-18\n",
      "   1.00000000e+00   9.99547210e-01   1.00000000e+00   2.57005860e-54\n",
      "   9.64577118e-01   1.00000000e+00   1.00000000e+00   1.00000000e+00\n",
      "   1.63621904e-06   5.89031252e-01   9.99994219e-01   1.36149431e-59\n",
      "   5.62890131e-01   1.00000000e+00   3.15235655e-04   1.30326900e-10\n",
      "   2.01575888e-10   9.86771379e-01]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate a model for estimating the parameters of the\n",
    "# true model based on the observations (X, Y) we just made\n",
    "# model = EM_algo_MM(hyperp, X, Y)\n",
    "model = EM_algo_MM(hyperp, X, Y)\n",
    "i, logl, r = model.EM_fit()\n",
    "print(\"Model fit (logl %.2f) after %d iterations (%s reached)\" % \\\n",
    "        (logl, i, r))\n",
    "print(\"\")\n",
    "print(\"MAP estimate of true model parameters:\")\n",
    "model.print_p()\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if possible, plot samples, true model and estimated model\n",
    "if pdata == 1:\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.scatter(X, Y, s=20, c='black', label=\"Training data\")\n",
    "#         plt.scatter(X_v, Y_v, s=20, c='orange', label=\"Validation data\")\n",
    "    x = arange(min(X)-0.1, max(X)+0.1, 0.1)\n",
    "#         print_linear_model(x, true_model.get_p()[\"phi\"], \\\n",
    "#                 true_model.get_p()[\"sigma2\"], 'red', \"True model\")\n",
    "#         print_linear_model(x, model.get_p()[\"phi\"], \\\n",
    "#                 model.get_p()[\"sigma2\"], 'blue', \"Predicted model\")\n",
    "\n",
    "    y = true_model.p[\"phi_1\"] * x\n",
    "    color = 'orange'\n",
    "    plt.plot(x, y, color, label=\"true1\")\n",
    "#     plt.fill_between(x, y + 1.96 * sqrt(true_model.p[\"sigma2_1\"]), y - 1.96 * sqrt(true_model.p[\"sigma2_1\"]), alpha=0.1, facecolor=color, interpolate=True)\n",
    "    \n",
    "    y = true_model.p[\"phi_2\"] * x\n",
    "    color = 'green'\n",
    "    plt.plot(x, y, color, label=\"true1\")\n",
    "#     plt.fill_between(x, y + 1.96 * sqrt(true_model.p[\"sigma2_2\"]), y - 1.96 * sqrt(true_model.p[\"sigma2_2\"]), alpha=0.1, facecolor=color, interpolate=True)\n",
    "\n",
    "    # Components\n",
    "    y = model.p[\"phi_1\"] * x\n",
    "    color = 'red'\n",
    "    plt.plot(x, y, color, label=\"component1\")\n",
    "    plt.fill_between(x, y + 1.96 * sqrt(model.p[\"sigma2_1\"]), y - 1.96 * sqrt(model.p[\"sigma2_1\"]), alpha=0.25, facecolor=color, interpolate=True)\n",
    "\n",
    "    y = model.p[\"phi_2\"] * x\n",
    "    color = 'blue'\n",
    "    plt.plot(x, y, color, label=\"component2\")\n",
    "    plt.fill_between(x, y + 1.96 * sqrt(model.p[\"sigma2_2\"]), y - 1.96 * sqrt(model.p[\"sigma2_2\"]), alpha=0.25, facecolor=color, interpolate=True)\n",
    "\n",
    "    plt.legend(loc=1)\n",
    "    plt.xlim(min(x), max(x))\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 50 training data and 50 validation data from true model:\n",
      "phi_2 = [ 0.14622796  0.17466192  0.23211332  0.02601663 -0.08892349  0.38066748\n",
      " -0.07461691 -0.37437487  0.0906503  -0.55028953  0.22270234 -0.07162377\n",
      " -0.04911523 -0.5516191   0.4399013  -0.07090167  0.21477018  0.09329735\n",
      "  0.12188289  0.04177689  0.21079448  0.47410063  0.35316802 -0.49521044\n",
      " -0.28802884]\n",
      "sigma2_1 = 0.17160297073388148\n",
      "sigma2_2 = 0.1268152034792153\n",
      "w = 0.3363261348567545\n",
      "phi_1 = [-0.61782296  0.31023782 -0.60281633 -0.15913919  0.19062736  0.04071882\n",
      " -0.06026341 -0.33077767  0.08511221 -0.35964656 -0.1046024   0.5401076\n",
      " -0.7233217   0.22564523  0.17583085  0.05363284 -0.17044155 -0.61704558\n",
      " -0.0827809   0.27138255 -0.47140316 -0.75335157 -0.0873071   0.16622004\n",
      "  0.30064356]\n",
      "gamma = [1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get hyperparameters for model\n",
    "hyperp = get_hyperp()\n",
    "# generate 50 training data and 20 validation data locations of dim=1\n",
    "ndata = 50\n",
    "ndata_v = 50\n",
    "pdata = 25\n",
    "X = generate_X(ndata, pdata)\n",
    "X_v = generate_X(ndata_v, pdata)\n",
    "\n",
    "true_model = EM_algo_MM(hyperp, ndata=ndata, pdata=pdata)\n",
    "Y, Z = generate_YZ(X, true_model)\n",
    "Y_v, Z_v = generate_YZ(X_v, true_model)\n",
    "print(\"Generated %d training data and %d validation data from true model:\" % \\\n",
    "    (ndata, ndata_v))\n",
    "true_model.print_p()\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'phi_2': 0, 'w': 0, 'phi_1': 0, 'sigma2_2': 0, 'sigma2_1': 0}\n",
      "0 0 1000\n",
      "{'phi_2': 0, 'w': 0, 'phi_1': 0, 'sigma2_2': 0, 'sigma2_1': 0}\n",
      "3.37453377128\n",
      "0.00951989469854\n"
     ]
    }
   ],
   "source": [
    "mm_cumulative_error = 0.0\n",
    "mm_max_diff = 0.0\n",
    "foodict = {'w': 0, 'phi_1': 0, 'phi_2': 0, 'sigma2_1': 0, 'sigma2_2': 0}\n",
    "bardict = {'w': 0, 'phi_1': 0, 'phi_2': 0, 'sigma2_1': 0, 'sigma2_2': 0}\n",
    "counter = 0\n",
    "counterOther = 0\n",
    "counterAlim = 0\n",
    "for truru in range(1000):\n",
    "    try:\n",
    "        # generate a model for estimating the parameters of the\n",
    "        # true model based on the observations (X, Y) we just made\n",
    "        model = EM_algo_MM(hyperp, X, Y)\n",
    "        i, logl, r = model.EM_fit()\n",
    "        if r == \"alim\":\n",
    "            counterAlim += 1\n",
    "#         print(\"Model fit (logl %.2f) after %d iterations (%s reached)\" % \\\n",
    "#                 (logl, i, r))\n",
    "#         print(\"\")\n",
    "#         print(\"MAP estimate of true model parameters:\")\n",
    "#         model.print_p()\n",
    "#         print(\"\")\n",
    "    except ValueError as e:\n",
    "        counter = counter + 1\n",
    "        foodict[str(e)] = foodict[str(e)] + 1\n",
    "    except RuntimeError as e:\n",
    "        counterOther = counterOther + 1\n",
    "        bardict[str(e)] = bardict[str(e)] + 1\n",
    "\n",
    "print(foodict)\n",
    "print(counter, counterOther, counterAlim)\n",
    "print(bardict)\n",
    "print(mm_cumulative_error)\n",
    "print(mm_max_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# {'phi_2': 0, 'w': 0, 'phi_1': 0, 'sigma2_2': 0, 'sigma2_1': 0}\n",
    "# 0 205 795\n",
    "# {'phi_2': 0, 'w': 0, 'phi_1': 0, 'sigma2_2': 94, 'sigma2_1': 111}\n",
    "# 118.136238357\n",
    "# 4.41033014787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "workedParams = []\n",
    "failedParams = []\n",
    "workedW = []\n",
    "failedW = []\n",
    "workedPhi1 = []\n",
    "failedPhi1 = []\n",
    "workedPhi2 = []\n",
    "failedPhi2 = []\n",
    "workedSigma1 = []\n",
    "failedSigma1 = []\n",
    "workedSigma2 = []\n",
    "failedSigma2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for opop in range(1000):\n",
    "    fail = False\n",
    "    model = EM_algo_MM(hyperp, X, Y)\n",
    "    try:\n",
    "        for trara in range(1000):\n",
    "            i, logl, r = model.EM_fit()\n",
    "    except Exception as e:\n",
    "        fail = True\n",
    "        failedW.append(model.p[\"w\"])\n",
    "        failedPhi1.append(model.p[\"phi_1\"])\n",
    "        failedPhi2.append(model.p[\"phi_2\"])\n",
    "        failedSigma1.append(model.p[\"sigma2_1\"])\n",
    "        failedSigma2.append(model.p[\"sigma2_2\"])\n",
    "        failedParams.append([model.p[\"w\"], model.p[\"phi_1\"], model.p[\"phi_2\"], model.p[\"sigma2_1\"], model.p[\"sigma2_2\"]])\n",
    "    else:\n",
    "        workedW.append(model.p[\"w\"])\n",
    "        workedPhi1.append(model.p[\"phi_1\"])\n",
    "        workedPhi2.append(model.p[\"phi_2\"])\n",
    "        workedSigma1.append(model.p[\"sigma2_1\"])\n",
    "        workedSigma2.append(model.p[\"sigma2_2\"])\n",
    "        workedParams.append([model.p[\"w\"], model.p[\"phi_1\"], model.p[\"phi_2\"], model.p[\"sigma2_1\"], model.p[\"sigma2_2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349, 651)"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(workedW), len(failedW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yo = []\n",
    "yo.extend([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 902,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.  ,  0.01,  0.02,  0.03,  0.04,  0.05,  0.06,  0.07,  0.08,\n",
       "        0.09,  0.1 ,  0.11,  0.12,  0.13,  0.14,  0.15,  0.16,  0.17,\n",
       "        0.18,  0.19,  0.2 ,  0.21,  0.22,  0.23,  0.24,  0.25,  0.26,\n",
       "        0.27,  0.28,  0.29,  0.3 ,  0.31,  0.32,  0.33,  0.34,  0.35,\n",
       "        0.36,  0.37,  0.38,  0.39,  0.4 ,  0.41,  0.42,  0.43,  0.44,\n",
       "        0.45,  0.46,  0.47,  0.48,  0.49,  0.5 ])"
      ]
     },
     "execution_count": 912,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fupfup = []\n",
    "fupfup.extend(np.array(failedW)[np.array(failedW) < 0.5])\n",
    "fupfup.extend(np.array(failedW)[np.array(failedW) >= 0.5] - 0.5)\n",
    "np.unique(np.array(fupfup).round(decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.3126867 ,  0.31667702,  0.68332298,  0.6873133 ]),\n",
       " array([-0.34693938, -0.16985928,  0.18014518,  0.21157547]),\n",
       " array([-0.34693938, -0.16985928,  0.18014518,  0.21157547]),\n",
       " array([ 0.13873261,  0.20763594,  0.3472129 ,  0.4250252 ]),\n",
       " array([ 0.13873261,  0.20763594,  0.3472129 ,  0.4250252 ]))"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(workedW).round(decimals=8)), np.unique(np.array(workedPhi1).round(decimals=8)), np.unique(np.array(workedPhi2).round(decimals=8)), np.unique(np.array(workedSigma1).round(decimals=8)), np.unique(np.array(workedSigma2).round(decimals=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# np.unique(np.array(workedW).round(decimals=8)), np.unique(np.array(failedW).round(decimals=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.unique(np.array(workedPhi1).round(decimals=8)), np.unique(np.array(failedPhi1).round(decimals=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.unique(np.array(workedPhi2).round(decimals=8)), np.unique(np.array(failedPhi2).round(decimals=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.unique(np.array(workedSigma1).round(decimals=8)), np.unique(np.array(failedSigma1).round(decimals=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "didn't fail\n"
     ]
    }
   ],
   "source": [
    "# # plot failure states\n",
    "# fail = False\n",
    "# model = EM_algo_MM(hyperp, X, Y)\n",
    "# try:\n",
    "#     for trara in range(1000):\n",
    "#         i, logl, r = model.EM_fit()\n",
    "# except Exception as e:\n",
    "#     fail = True\n",
    "#     failedW.append(model.p[\"w\"])\n",
    "#     failedPhi1.append(model.p[\"phi_1\"])\n",
    "#     failedPhi2.append(model.p[\"phi_2\"])\n",
    "#     failedSigma1.append(model.p[\"sigma2_1\"])\n",
    "#     failedSigma2.append(model.p[\"sigma2_2\"])\n",
    "#     failedParams.append([model.p[\"w\"], model.p[\"phi_1\"], model.p[\"phi_2\"], model.p[\"sigma2_1\"], model.p[\"sigma2_2\"]])\n",
    "#     print(\"failed!\", e)\n",
    "\n",
    "# if fail:\n",
    "#     # if possible, plot samples, true model and estimated model\n",
    "#     if pdata == 1:\n",
    "#         plt.figure(figsize=(20,10))\n",
    "#         plt.scatter(X, Y, s=20, c='black', label=\"Training data\")\n",
    "#     #         plt.scatter(X_v, Y_v, s=20, c='orange', label=\"Validation data\")\n",
    "#         x = arange(min(X)-0.1, max(X)+0.1, 0.1)\n",
    "#     #         print_linear_model(x, true_model.get_p()[\"phi\"], \\\n",
    "#     #                 true_model.get_p()[\"sigma2\"], 'red', \"True model\")\n",
    "#     #         print_linear_model(x, model.get_p()[\"phi\"], \\\n",
    "#     #                 model.get_p()[\"sigma2\"], 'blue', \"Predicted model\")\n",
    "\n",
    "#         y = true_model.p[\"phi_1\"] * x\n",
    "#         color = 'orange'\n",
    "#         plt.plot(x, y, color, label=\"true1\")\n",
    "#     #     plt.fill_between(x, y + 1.96 * sqrt(true_model.p[\"sigma2_1\"]), y - 1.96 * sqrt(true_model.p[\"sigma2_1\"]), alpha=0.1, facecolor=color, interpolate=True)\n",
    "\n",
    "#         y = true_model.p[\"phi_2\"] * x\n",
    "#         color = 'green'\n",
    "#         plt.plot(x, y, color, label=\"true1\")\n",
    "#     #     plt.fill_between(x, y + 1.96 * sqrt(true_model.p[\"sigma2_2\"]), y - 1.96 * sqrt(true_model.p[\"sigma2_2\"]), alpha=0.1, facecolor=color, interpolate=True)\n",
    "\n",
    "#         # Components\n",
    "#         y = model.p[\"phi_1\"] * x\n",
    "#         color = 'red'\n",
    "#         plt.plot(x, y, color, label=\"component1\")\n",
    "#         plt.fill_between(x, y + 1.96 * sqrt(model.p[\"sigma2_1\"]), y - 1.96 * sqrt(model.p[\"sigma2_1\"]), alpha=0.25, facecolor=color, interpolate=True)\n",
    "\n",
    "#         y = model.p[\"phi_2\"] * x\n",
    "#         color = 'blue'\n",
    "#         plt.plot(x, y, color, label=\"component2\")\n",
    "#         plt.fill_between(x, y + 1.96 * sqrt(model.p[\"sigma2_2\"]), y - 1.96 * sqrt(model.p[\"sigma2_2\"]), alpha=0.25, facecolor=color, interpolate=True)\n",
    "\n",
    "#         plt.legend(loc=1)\n",
    "#         plt.xlim(min(x), max(x))\n",
    "#         plt.xlabel(\"x\")\n",
    "#         plt.ylabel(\"y\")\n",
    "#         plt.show()\n",
    "# else:\n",
    "#     workedW.append(model.p[\"w\"])\n",
    "#     workedPhi1.append(model.p[\"phi_1\"])\n",
    "#     workedPhi2.append(model.p[\"phi_2\"])\n",
    "#     workedSigma1.append(model.p[\"sigma2_1\"])\n",
    "#     workedSigma2.append(model.p[\"sigma2_2\"])\n",
    "#     workedParams.append([model.p[\"w\"], model.p[\"phi_1\"], model.p[\"phi_2\"], model.p[\"sigma2_1\"], model.p[\"sigma2_2\"]])\n",
    "#     print(\"didn't fail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moo_workedParams = []\n",
    "moo_failedParams = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for opop in range(1000):\n",
    "    fail = False\n",
    "    model = EM_algo_MM(hyperp, X, Y)\n",
    "    initParams = (model.p[\"w\"], model.p[\"phi_1\"], model.p[\"phi_2\"], model.p[\"sigma2_1\"], model.p[\"sigma2_2\"])\n",
    "    try:\n",
    "        for trara in range(50):\n",
    "            i, logl, r = model.EM_fit()\n",
    "    except Exception as e:\n",
    "        fail = True\n",
    "        moo_failedParams.append(initParams)\n",
    "    else:\n",
    "        moo_workedParams.append(initParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.unique(np.array( list(map(lambda tup: tup[4], moo_workedParams)) ).round(decimals=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.unique(np.array( list(map(lambda tup: tup[4], moo_failedParams)) ).round(decimals=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logl      before     after\n",
      "Total    -99.066 > -104.285   diff:  -5.219\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "w",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-724-b460d7c8373d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# model = EM_algo_MM(hyperp, X, Y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEM_algo_MM_ML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEM_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model fit (logl %.2f) after %d iterations (%s reached)\"\u001b[0m \u001b[0;34m%\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mlogl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-626-f0bb6e58a1be>\u001b[0m in \u001b[0;36mEM_fit\u001b[0;34m(self, alim, maxit)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mlogl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEM_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mlogl2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0madiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogl2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-723-379b99d5d01e>\u001b[0m in \u001b[0;36mEM_iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;31m#         newlogl, ll = self.logl()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;31m#         self.debug_logl(self.cll, ll)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_logl_increased\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-626-f0bb6e58a1be>\u001b[0m in \u001b[0;36massert_logl_increased\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;31m#             if self.current_ilogl - inewlogl > 1e-3:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;31m#                 raise ValueError(\"%s\" % (event))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;31m#             raise ValueError(\"%s\" % (event))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;31m#             raise ValueError(\"logl decreased after %s\" % (event))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: w"
     ]
    }
   ],
   "source": [
    "# generate a model for estimating the parameters of the\n",
    "# true model based on the observations (X, Y) we just made\n",
    "# model = EM_algo_MM(hyperp, X, Y)\n",
    "model = EM_algo_MM_ML(hyperp, X, Y)\n",
    "i, logl, r = model.EM_fit()\n",
    "print(\"Model fit (logl %.2f) after %d iterations (%s reached)\" % \\\n",
    "        (logl, i, r))\n",
    "print(\"\")\n",
    "print(\"MAP estimate of true model parameters:\")\n",
    "model.print_p()\n",
    "print(\"\")\n",
    "\n",
    "# if possible, plot samples, true model and estimated model\n",
    "if pdata == 1:\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.scatter(X, Y, s=20, c='black', label=\"Training data\")\n",
    "#         plt.scatter(X_v, Y_v, s=20, c='orange', label=\"Validation data\")\n",
    "    x = arange(min(X)-0.1, max(X)+0.1, 0.1)\n",
    "#         print_linear_model(x, true_model.get_p()[\"phi\"], \\\n",
    "#                 true_model.get_p()[\"sigma2\"], 'red', \"True model\")\n",
    "#         print_linear_model(x, model.get_p()[\"phi\"], \\\n",
    "#                 model.get_p()[\"sigma2\"], 'blue', \"Predicted model\")\n",
    "\n",
    "    y = true_model.p[\"phi_1\"] * x\n",
    "    color = 'orange'\n",
    "    plt.plot(x, y, color, label=\"true1\")\n",
    "#     plt.fill_between(x, y + 1.96 * sqrt(true_model.p[\"sigma2_1\"]), y - 1.96 * sqrt(true_model.p[\"sigma2_1\"]), alpha=0.1, facecolor=color, interpolate=True)\n",
    "    \n",
    "    y = true_model.p[\"phi_2\"] * x\n",
    "    color = 'green'\n",
    "    plt.plot(x, y, color, label=\"true1\")\n",
    "#     plt.fill_between(x, y + 1.96 * sqrt(true_model.p[\"sigma2_2\"]), y - 1.96 * sqrt(true_model.p[\"sigma2_2\"]), alpha=0.1, facecolor=color, interpolate=True)\n",
    "\n",
    "    # Components\n",
    "    y = model.p[\"phi_1\"] * x\n",
    "    color = 'red'\n",
    "    plt.plot(x, y, color, label=\"component1\")\n",
    "    plt.fill_between(x, y + 1.96 * sqrt(model.p[\"sigma2_1\"]), y - 1.96 * sqrt(model.p[\"sigma2_1\"]), alpha=0.25, facecolor=color, interpolate=True)\n",
    "\n",
    "    y = model.p[\"phi_2\"] * x\n",
    "    color = 'blue'\n",
    "    plt.plot(x, y, color, label=\"component2\")\n",
    "    plt.fill_between(x, y + 1.96 * sqrt(model.p[\"sigma2_2\"]), y - 1.96 * sqrt(model.p[\"sigma2_2\"]), alpha=0.25, facecolor=color, interpolate=True)\n",
    "\n",
    "    plt.legend(loc=1)\n",
    "    plt.xlim(min(x), max(x))\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#52.6616091784 / 100 sum_gamma/N\n",
    "#45.7714188785 / 100 2sum_gamma/2N\n",
    "#54.0407783949 / 1000 noprior\n",
    "\n",
    "# w calc: sum_gamma/N and priors\n",
    "# P=25\n",
    "# 481.200431063/1000\n",
    "# 1.60766953606\n",
    "# P=1\n",
    "# 1338.35145532\n",
    "# 8.96063745013\n",
    "\n",
    "\n",
    "# w calc: 2sum_gamma/2N and priors\n",
    "# P=25\n",
    "# 479.509016854\n",
    "# 1.48591032263\n",
    "# P=1\n",
    "# 1251.83407586\n",
    "# 7.67944230767\n",
    "\n",
    "\n",
    "# w calc: sum_gamma/N no priors\n",
    "# P=25\n",
    "# 476.736018111\n",
    "# 1.67545427466\n",
    "# P=1\n",
    "# 1609.611982\n",
    "# 7.16195979147\n",
    "\n",
    "\n",
    "# w calc: sum_gamma/N no priors\n",
    "# P=1, checking alim (was 846)\n",
    "# {'phi_2': 0, 'w': 0, 'phi_1': 0, 'sigma2_2': 0, 'sigma2_1': 0}\n",
    "# 0 154 846\n",
    "# {'phi_2': 0, 'w': 154, 'phi_1': 0, 'sigma2_2': 0, 'sigma2_1': 0}\n",
    "# 10846.6431968\n",
    "# 18.0166271427"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting program\n",
      "\n",
      "Generated 20 training data and 50 validation data from true model:\n",
      "phi    : (-0.33, -0.14, 0.65)\n",
      "sigma2 : 0.147\n",
      "\n",
      "phie (3,)\n",
      "err (20,)\n",
      "phie (3,)\n",
      "err (20,)\n",
      "sumxx <class 'numpy.ndarray'> sumxy <class 'numpy.ndarray'> sigma_mu <class 'numpy.ndarray'> sigma_phi_inv <class 'numpy.ndarray'>\n",
      "sumxx (3, 3) sumxy (3,) sigma_mu (3,) sigma_phi_inv (3, 3)\n",
      "phie (3,)\n",
      "err (20,)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EM_algo_LM' object has no attribute 'icll'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-217-b6f321352cd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-217-b6f321352cd2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting program\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtest_LM_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-217-b6f321352cd2>\u001b[0m in \u001b[0;36mtest_LM_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# true model based on the observations (X, Y) we just made\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEM_algo_LM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEM_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model fit (logl %.2f) after %d iterations (%s reached)\"\u001b[0m \u001b[0;34m%\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mlogl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-136-115271e1f262>\u001b[0m in \u001b[0;36mEM_fit\u001b[0;34m(self, alim, maxit)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mlogl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEM_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mlogl2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0madiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogl2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-211-5efe0448c240>\u001b[0m in \u001b[0;36mEM_iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sumxx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msumxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sumxy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msumxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sigma_mu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma_mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sigma_phi_inv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma_phi_inv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sumxx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msumxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sumxy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msumxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sigma_mu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sigma_phi_inv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_phi_inv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_logl_increased\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"phi update\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# sigma2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-136-115271e1f262>\u001b[0m in \u001b[0;36massert_logl_increased\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"logl decreased after %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_logl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewlogl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0micll\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_ilogl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0micll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincompletelogl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EM_algo_LM' object has no attribute 'icll'"
     ]
    }
   ],
   "source": [
    "# Aalto University, School of Science\n",
    "# T-61.5140 Machine Learning: Advanced probabilistic Methods\n",
    "# Author: antti.kangasraasio@aalto.fi, 2016\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "        Executed when program is run.\n",
    "    \"\"\"\n",
    "    print(\"Starting program\")\n",
    "    print(\"\")\n",
    "    test_LM_model()\n",
    "\n",
    "\n",
    "def test_LM_model():\n",
    "    \"\"\"\n",
    "        Example that demonstrates how to call the model.\n",
    "    \"\"\"\n",
    "    # get hyperparameters for model\n",
    "    hyperp = get_hyperp()\n",
    "    # generate 50 training data and 20 validation data locations of dim=1\n",
    "    ndata = 20\n",
    "    ndata_v = 50\n",
    "    pdata = 3\n",
    "    X = generate_X(ndata, pdata)\n",
    "    X_v = generate_X(ndata_v, pdata)\n",
    "    # intialize true model randomly and draw observations from it\n",
    "    true_model = EM_algo_LM(hyperp, ndata=ndata, pdata=pdata)\n",
    "    Y, Z = generate_YZ(X, true_model)\n",
    "    Y_v, Z_v = generate_YZ(X_v, true_model)\n",
    "    print(\"Generated %d training data and %d validation data from true model:\" % \\\n",
    "            (ndata, ndata_v))\n",
    "    true_model.print_p()\n",
    "    print(\"\")\n",
    "\n",
    "    # generate a model for estimating the parameters of the\n",
    "    # true model based on the observations (X, Y) we just made\n",
    "    model = EM_algo_LM(hyperp, X, Y)\n",
    "    i, logl, r = model.EM_fit()\n",
    "    print(\"Model fit (logl %.2f) after %d iterations (%s reached)\" % \\\n",
    "            (logl, i, r))\n",
    "    print(\"\")\n",
    "    print(\"MAP estimate of true model parameters:\")\n",
    "    model.print_p()\n",
    "    print(\"\")\n",
    "\n",
    "    # crossvalidate the estimated model with the validation data\n",
    "    fit_params = model.get_p()\n",
    "    model_v = EM_algo_LM(hyperp, X_v, Y_v)\n",
    "    model_v.set_p(fit_params)\n",
    "    logl, ll = model_v.logl()\n",
    "    print(\"Crossvalidated logl: %.2f\" % (logl))\n",
    "\n",
    "    # if possible, plot samples, true model and estimated model\n",
    "    if pdata != 1:\n",
    "        return\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.scatter(X, Y, s=20, c='black', label=\"Training data\")\n",
    "    plt.scatter(X_v, Y_v, s=20, c='orange', label=\"Validation data\")\n",
    "    x = arange(min(X)-0.1, max(X)+0.1, 0.1)\n",
    "    print_linear_model(x, true_model.get_p()[\"phi\"], \\\n",
    "            true_model.get_p()[\"sigma2\"], 'red', \"True model\")\n",
    "    print_linear_model(x, model.get_p()[\"phi\"], \\\n",
    "            model.get_p()[\"sigma2\"], 'blue', \"Predicted model\")\n",
    "    plt.legend(loc=1)\n",
    "    plt.xlim(min(x), max(x))\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "def print_linear_model(x, phi, sigma2, color, label):\n",
    "    \"\"\"\n",
    "        Print linear model mean and 95% confidence interval.\n",
    "    \"\"\"\n",
    "    y = phi * x\n",
    "    plt.plot(x, y, color, label=label)\n",
    "    plt.fill_between(x, y + 1.96 * sqrt(sigma2), y - 1.96 * sqrt(sigma2), \\\n",
    "            alpha=0.25, facecolor=color, interpolate=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = generate_X(10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.91954461,  0.2400352 ],\n",
       "       [ 2.33650195,  1.81126434],\n",
       "       [-0.08133542,  0.06118832],\n",
       "       [-1.33545433, -0.86719239],\n",
       "       [ 1.66719011, -0.57531528],\n",
       "       [-0.30577782,  0.06323988],\n",
       "       [ 0.99608716, -0.33705257],\n",
       "       [-0.65754579, -0.1670884 ],\n",
       "       [ 1.05556896,  0.3179948 ],\n",
       "       [ 1.17714858,  1.69832692]])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.05556896,  0.3179948 ])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[8,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 14.892341  ,   6.29490444],\n",
       "       [  6.29490444,   7.55600699]])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T.dot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_model = EM_algo_LM(get_hyperp(), ndata=10, pdata=2)\n",
    "Y, Z = generate_YZ(X, true_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.63206963, -0.67963419])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T.dot(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 14.892341  ,   6.29490444],\n",
       "       [  6.29490444,   7.55600699]])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T.dot(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": true
  },
  "toc_position": {
   "left": "1195.078125px",
   "right": "20px",
   "top": "120px",
   "width": "186px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
